I1211 01:10:29.026525 92593 rpc_service_base.h:46] RPC service is listening on 0.0.0.0:10001
I1211 01:10:31.593684 92598 scheduler.cpp:98] Register server: node_type: BACKEND_NODE
node_id: 3214520406
server_port: "8001"
rpc_port: "8002"
gpu_device_name: "Tesla_V100S-PCIE-32GB"
gpu_available_memory: 33650376704
gpu_uuid: "fcf0dc04-2c7f-7570-499b-47b29c6d534c"
I1211 01:10:33.043171 92601 scheduler.cpp:98] Register server: node_id: 2750509680
server_port: "9001"
rpc_port: "9002"
I1211 01:10:33.043632 92600 model_db.cpp:283] Load model DB from /workdir/models/db/model_db.yml
I1211 01:10:33.044454 92600 backend_delegate.cpp:183] Backend 3214520406 loads fake:fake_0:1:224x224:1123, batch 8, max batch 8, max duty cycle 3708.32 us, throughput 2157.31 req/s. Backend exec cycle 3708.32 us, duty cycle: 3708.32 us
I1211 01:11:00.028893 92593 scheduler.cpp:832] Epoch schedule
I1211 01:11:00.029004 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 1
I1211 01:11:00.029031 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/2157.31/1, total share: 1
I1211 01:11:15.030134 92593 scheduler.cpp:832] Epoch schedule
I1211 01:11:15.030190 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 0.919651 (last: 0.919651, mean: 0.669105, std: 0.22667), throughput: 2157.31
I1211 01:11:15.030226 92593 backend_delegate.cpp:341] Backend 3214520406 updates fake:fake_0:1:224x224:1123, batch 2, max batch 8, new throughput 1.78691
I1211 01:11:15.031633 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00146307
I1211 01:11:15.031656 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/1.78691/1, total share: 1
I1211 01:11:25.032488 92593 scheduler.cpp:832] Epoch schedule
I1211 01:11:25.032557 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 0.923185 (last: 0.923185, mean: 0.838726, std: 0.0805351), throughput: 1.78691
I1211 01:11:25.033172 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00146307
I1211 01:11:25.033192 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/1.78691/1, total share: 1
I1211 01:11:35.034029 92593 scheduler.cpp:832] Epoch schedule
I1211 01:11:35.034072 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 0.893829 (last: 0.893829, mean: 0.899536, std: 0.0377825), throughput: 1.78691
I1211 01:11:35.034451 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00146307
I1211 01:11:35.034471 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/1.78691/1, total share: 1
I1211 01:11:45.035315 92593 scheduler.cpp:832] Epoch schedule
I1211 01:11:45.035372 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 0.960942 (last: 0.960942, mean: 0.9209, std: 0.0312848), throughput: 1.78691
I1211 01:11:45.035883 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00146307
I1211 01:11:45.035903 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/1.78691/1, total share: 1
I1211 01:11:55.037076 92593 scheduler.cpp:832] Epoch schedule
I1211 01:11:55.037138 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 0.938375 (last: 0.938375, mean: 0.928759, std: 0.0284156), throughput: 1.78691
I1211 01:11:55.037634 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00146307
I1211 01:11:55.037654 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/1.78691/1, total share: 1
I1211 01:12:05.038717 92593 scheduler.cpp:832] Epoch schedule
I1211 01:12:05.038771 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 0.899417 (last: 0.899417, mean: 0.931651, std: 0.0286415), throughput: 1.78691
I1211 01:12:05.039371 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00146307
I1211 01:12:05.039391 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/1.78691/1, total share: 1
I1211 01:12:15.040307 92593 scheduler.cpp:832] Epoch schedule
I1211 01:12:15.040357 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 0.962998 (last: 0.962998, mean: 0.932714, std: 0.0288009), throughput: 1.78691
I1211 01:12:15.040868 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00146307
I1211 01:12:15.040889 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/1.78691/1, total share: 1
I1211 01:12:25.041839 92593 scheduler.cpp:832] Epoch schedule
I1211 01:12:25.041893 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 1.26384 (last: 1.26384, mean: 0.965335, std: 0.0965285), throughput: 1.78691
I1211 01:12:25.042346 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00146307
I1211 01:12:25.042374 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/1.78691/1, total share: 1
I1211 01:12:35.043162 92593 scheduler.cpp:832] Epoch schedule
I1211 01:12:35.043244 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 2.90216 (last: 2.90216, mean: 1.40028, std: 0.66483), throughput: 1.78691
I1211 01:12:35.043279 92593 backend_delegate.cpp:341] Backend 3214520406 updates fake:fake_0:1:224x224:1123, batch 4, max batch 8, new throughput 3.57603
I1211 01:12:35.044099 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00208107
I1211 01:12:35.044119 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/3.57603/1, total share: 1
I1211 01:12:45.044883 92593 scheduler.cpp:832] Epoch schedule
I1211 01:12:45.044939 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 4.37564 (last: 4.37564, mean: 2.37908, std: 1.24314), throughput: 3.57603
I1211 01:12:45.044976 92593 backend_delegate.cpp:341] Backend 3214520406 updates fake:fake_0:1:224x224:1123, batch 5, max batch 8, new throughput 4.47142
I1211 01:12:45.045855 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00239036
I1211 01:12:45.045876 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/4.47142/1, total share: 1
I1211 01:12:55.046640 92593 scheduler.cpp:832] Epoch schedule
I1211 01:12:55.046696 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 5.68247 (last: 5.68247, mean: 3.78116, std: 1.31041), throughput: 4.47142
I1211 01:12:55.046733 92593 backend_delegate.cpp:341] Backend 3214520406 updates fake:fake_0:1:224x224:1123, batch 7, max batch 8, new throughput 6.26385
I1211 01:12:55.047611 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.0030095
I1211 01:12:55.047633 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/6.26385/1, total share: 1
I1211 01:13:25.049930 92593 scheduler.cpp:832] Epoch schedule
I1211 01:13:25.050000 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 5.07355 (last: 5.07355, mean: 5.84336, std: 0.401419), throughput: 6.26385
I1211 01:13:25.050038 92593 backend_delegate.cpp:341] Backend 3214520406 updates fake:fake_0:1:224x224:1123, batch 6, max batch 8, new throughput 5.36735
I1211 01:13:25.051012 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00269983
I1211 01:13:25.051034 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/5.36735/1, total share: 1
I1211 01:13:35.051776 92593 scheduler.cpp:832] Epoch schedule
I1211 01:13:35.051847 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 4.22478 (last: 4.22478, mean: 5.36619, std: 0.693832), throughput: 5.36735
I1211 01:13:35.051899 92593 backend_delegate.cpp:341] Backend 3214520406 updates fake:fake_0:1:224x224:1123, batch 5, max batch 8, new throughput 4.47142
I1211 01:13:35.052788 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00239036
I1211 01:13:35.052807 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/4.47142/1, total share: 1
I1211 01:13:58.054728 92593 scheduler.cpp:832] Epoch schedule
I1211 01:13:58.054798 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 3.56501 (last: 3.56501, mean: 4.01508, std: 0.294051), throughput: 4.47142
I1211 01:13:58.054843 92593 backend_delegate.cpp:341] Backend 3214520406 updates fake:fake_0:1:224x224:1123, batch 4, max batch 8, new throughput 3.57603
I1211 01:13:58.055788 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00208107
I1211 01:13:58.055807 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/3.57603/1, total share: 1
I1211 01:14:27.058265 92593 scheduler.cpp:832] Epoch schedule
I1211 01:14:27.058336 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 4.1181 (last: 4.1181, mean: 3.38002, std: 0.275261), throughput: 3.57603
I1211 01:14:27.058409 92593 backend_delegate.cpp:341] Backend 3214520406 updates fake:fake_0:1:224x224:1123, batch 5, max batch 8, new throughput 4.47142
I1211 01:14:27.059360 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00239036
I1211 01:14:27.059381 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/4.47142/1, total share: 1
I1211 01:14:37.060197 92593 scheduler.cpp:832] Epoch schedule
I1211 01:14:37.060290 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 4.98093 (last: 4.98093, mean: 3.76954, std: 0.637848), throughput: 4.47142
I1211 01:14:37.060348 92593 backend_delegate.cpp:341] Backend 3214520406 updates fake:fake_0:1:224x224:1123, batch 6, max batch 8, new throughput 5.36735
I1211 01:14:37.061193 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00269983
I1211 01:14:37.061214 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/5.36735/1, total share: 1
I1211 01:15:07.063661 92593 scheduler.cpp:832] Epoch schedule
I1211 01:15:07.063735 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 4.5243 (last: 4.5243, mean: 5.35272, std: 0.285), throughput: 5.36735
I1211 01:15:07.064546 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00269983
I1211 01:15:07.064579 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/5.36735/1, total share: 1
I1211 01:15:17.065654 92593 scheduler.cpp:832] Epoch schedule
I1211 01:15:17.065693 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 2.23273 (last: 2.23273, mean: 4.68856, std: 1.17749), throughput: 5.36735
I1211 01:15:17.065727 92593 backend_delegate.cpp:341] Backend 3214520406 updates fake:fake_0:1:224x224:1123, batch 3, max batch 8, new throughput 2.68119
I1211 01:15:17.066474 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00177198
I1211 01:15:17.066495 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/2.68119/1, total share: 1
I1211 01:15:27.067489 92593 scheduler.cpp:832] Epoch schedule
I1211 01:15:27.067538 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 1.45349 (last: 1.45349, mean: 3.47502, std: 1.61315), throughput: 2.68119
I1211 01:15:27.067572 92593 backend_delegate.cpp:341] Backend 3214520406 updates fake:fake_0:1:224x224:1123, batch 2, max batch 8, new throughput 1.78691
I1211 01:15:27.068322 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00146307
I1211 01:15:27.068342 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/1.78691/1, total share: 1
I1211 01:15:37.069490 92593 scheduler.cpp:832] Epoch schedule
I1211 01:15:37.069525 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 1.12814 (last: 1.12814, mean: 2.06916, std: 0.947446), throughput: 1.78691
I1211 01:15:37.069900 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00146307
I1211 01:15:37.069931 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/1.78691/1, total share: 1
I1211 01:15:47.071089 92593 scheduler.cpp:832] Epoch schedule
I1211 01:15:47.071139 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 0.983351 (last: 0.983351, mean: 1.35118, std: 0.353735), throughput: 1.78691
I1211 01:15:47.071616 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00146307
I1211 01:15:47.071635 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/1.78691/1, total share: 1
I1211 01:15:57.072588 92593 scheduler.cpp:832] Epoch schedule
I1211 01:15:57.072656 92593 scheduler.cpp:861] fake:fake_0:1:224x224:1123 estimate rps: 0.993875 (last: 0.993875, mean: 1.08705, std: 0.12391), throughput: 1.78691
I1211 01:15:57.073189 92593 scheduler.cpp:1120] Total used GPUs: 1
Backend 3214520406: 0.00146307
I1211 01:15:57.073210 92593 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:1123: 3214520406/1.78691/1, total share: 1
*** Aborted at 1639185366 (unix time) try "date -d @1639185366" if you are using GNU date ***
I1211 01:16:06.699064 92598 scheduler.cpp:115] Unregister FRONTEND_NODE 2750509680
I1211 01:16:06.699054 92599 scheduler.cpp:115] Unregister BACKEND_NODE 3214520406
I1211 01:16:06.699123 92598 scheduler.cpp:442] Remove frontend 2750509680
I1211 01:16:06.699265 92598 scheduler.cpp:656] Remove model session: fake:fake_0:1:224x224:1123
I1211 01:16:06.699272 92598 backend_delegate.cpp:290] Backend 3214520406 unload model: fake:fake_0:1:224x224:1123
PC: @                0x0 (unknown)
*** SIGTERM (@0x1696f) received by PID 92593 (TID 0x7ffa75469f00) from PID 92527; stack trace: ***
I1211 01:16:06.700281 92599 scheduler.cpp:454] Remove backend 3214520406
    @     0x7ffa74168980 (unknown)
    @     0x7ffa74167d50 __GI___nanosleep
    @     0x563cde5e9f0d std::this_thread::sleep_for<>()
    @     0x563cde5cd269 nexus::scheduler::Scheduler::Run()
    @     0x563cde61c781 main
    @     0x7ffa6f3ddbf7 __libc_start_main
    @     0x563cde598eaa _start
    @                0x0 (unknown)
