Log file created at: 2021/12/11 06:21:35
Running on machine: 938168e9835c
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1211 06:21:35.392539 151265 rpc_service_base.h:46] RPC service is listening on 0.0.0.0:10001
I1211 06:21:37.960794 151270 scheduler.cpp:98] Register server: node_type: BACKEND_NODE
node_id: 503253232
server_port: "8001"
rpc_port: "8002"
gpu_device_name: "Tesla_V100S-PCIE-32GB"
gpu_available_memory: 33650376704
gpu_uuid: "fcf0dc04-2c7f-7570-499b-47b29c6d534c"
I1211 06:21:39.408779 151272 scheduler.cpp:98] Register server: node_id: 2932558800
server_port: "9001"
rpc_port: "9002"
I1211 06:21:39.409271 151273 model_db.cpp:283] Load model DB from /workdir/models/db/model_db.yml
I1211 06:21:39.410090 151273 backend_delegate.cpp:183] Backend 503253232 loads fake:fake_0:1:224x224:163, batch 8, max batch 8, max duty cycle 615.918 us, throughput 12988.7 req/s. Backend exec cycle 615.918 us, duty cycle: 615.918 us
I1211 06:22:06.396011 151265 scheduler.cpp:832] Epoch schedule
I1211 06:22:06.396126 151265 scheduler.cpp:1120] Total used GPUs: 1
Backend 503253232: 1
I1211 06:22:06.396152 151265 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:163: 503253232/12988.7/1, total share: 1
I1211 06:22:21.397336 151265 scheduler.cpp:832] Epoch schedule
I1211 06:22:21.397397 151265 scheduler.cpp:861] fake:fake_0:1:224x224:163 estimate rps: 7.1305 (last: 7.1305, mean: 6.18217, std: 1.82565), throughput: 12988.7
I1211 06:22:21.397428 151265 backend_delegate.cpp:341] Backend 503253232 updates fake:fake_0:1:224x224:163, batch 2, max batch 8, new throughput 12.4503
I1211 06:22:21.398857 151265 scheduler.cpp:1120] Total used GPUs: 1
Backend 503253232: 0.00154918
I1211 06:22:21.398882 151265 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:163: 503253232/12.4503/1, total share: 1
I1211 06:22:31.399636 151265 scheduler.cpp:832] Epoch schedule
I1211 06:22:31.399669 151265 scheduler.cpp:861] fake:fake_0:1:224x224:163 estimate rps: 9.89201 (last: 9.89201, mean: 7.94366, std: 1.80306), throughput: 12.4503
I1211 06:22:31.400130 151265 scheduler.cpp:1120] Total used GPUs: 1
Backend 503253232: 0.00154918
I1211 06:22:31.400156 151265 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:163: 503253232/12.4503/1, total share: 1
I1211 06:22:41.400985 151265 scheduler.cpp:832] Epoch schedule
I1211 06:22:41.401046 151265 scheduler.cpp:861] fake:fake_0:1:224x224:163 estimate rps: 9.20561 (last: 9.20561, mean: 8.92052, std: 1.77194), throughput: 12.4503
I1211 06:22:41.401679 151265 scheduler.cpp:1120] Total used GPUs: 1
Backend 503253232: 0.00154918
I1211 06:22:41.401719 151265 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:163: 503253232/12.4503/1, total share: 1
I1211 06:22:51.402483 151265 scheduler.cpp:832] Epoch schedule
I1211 06:22:51.402520 151265 scheduler.cpp:861] fake:fake_0:1:224x224:163 estimate rps: 6.99229 (last: 6.99229, mean: 9.26662, std: 1.32442), throughput: 12.4503
I1211 06:22:51.403025 151265 scheduler.cpp:1120] Total used GPUs: 1
Backend 503253232: 0.00154918
I1211 06:22:51.403053 151265 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:163: 503253232/12.4503/1, total share: 1
I1211 06:23:01.403893 151265 scheduler.cpp:832] Epoch schedule
I1211 06:23:01.403954 151265 scheduler.cpp:861] fake:fake_0:1:224x224:163 estimate rps: 6.89973 (last: 6.89973, mean: 8.20267, std: 1.4748), throughput: 12.4503
I1211 06:23:01.404443 151265 scheduler.cpp:1120] Total used GPUs: 1
Backend 503253232: 0.00154918
I1211 06:23:01.404466 151265 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:163: 503253232/12.4503/1, total share: 1
I1211 06:23:11.405292 151265 scheduler.cpp:832] Epoch schedule
I1211 06:23:11.405336 151265 scheduler.cpp:861] fake:fake_0:1:224x224:163 estimate rps: 6.23476 (last: 6.23476, mean: 7.01456, std: 0.818581), throughput: 12.4503
I1211 06:23:11.405767 151265 scheduler.cpp:1120] Total used GPUs: 1
Backend 503253232: 0.00154918
I1211 06:23:11.405792 151265 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:163: 503253232/12.4503/1, total share: 1
I1211 06:23:21.406574 151265 scheduler.cpp:832] Epoch schedule
I1211 06:23:21.406641 151265 scheduler.cpp:861] fake:fake_0:1:224x224:163 estimate rps: 6.54684 (last: 6.54684, mean: 6.82247, std: 0.675852), throughput: 12.4503
I1211 06:23:21.407164 151265 scheduler.cpp:1120] Total used GPUs: 1
Backend 503253232: 0.00154918
I1211 06:23:21.407183 151265 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:163: 503253232/12.4503/1, total share: 1
I1211 06:23:31.407985 151265 scheduler.cpp:832] Epoch schedule
I1211 06:23:31.408015 151265 scheduler.cpp:861] fake:fake_0:1:224x224:163 estimate rps: 7.60235 (last: 7.60235, mean: 7.48846, std: 1.30116), throughput: 12.4503
I1211 06:23:31.408358 151265 scheduler.cpp:1120] Total used GPUs: 1
Backend 503253232: 0.00154918
I1211 06:23:31.408376 151265 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:163: 503253232/12.4503/1, total share: 1
I1211 06:23:41.409232 151265 scheduler.cpp:832] Epoch schedule
I1211 06:23:41.409327 151265 scheduler.cpp:861] fake:fake_0:1:224x224:163 estimate rps: 9.07732 (last: 9.07732, mean: 8.28909, std: 1.27999), throughput: 12.4503
I1211 06:23:41.409862 151265 scheduler.cpp:1120] Total used GPUs: 1
Backend 503253232: 0.00154918
I1211 06:23:41.409891 151265 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:163: 503253232/12.4503/1, total share: 1
I1211 06:23:51.410950 151265 scheduler.cpp:832] Epoch schedule
I1211 06:23:51.410995 151265 scheduler.cpp:861] fake:fake_0:1:224x224:163 estimate rps: 4.50538 (last: 4.50538, mean: 7.9547, std: 1.72875), throughput: 12.4503
I1211 06:23:51.411032 151265 backend_delegate.cpp:341] Backend 503253232 updates fake:fake_0:1:224x224:163, batch 1, max batch 8, new throughput 6.22279
I1211 06:23:51.411815 151265 scheduler.cpp:1120] Total used GPUs: 1
Backend 503253232: 0.0011679
I1211 06:23:51.411834 151265 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:163: 503253232/6.22279/1, total share: 1
I1211 06:24:01.412783 151265 scheduler.cpp:832] Epoch schedule
I1211 06:24:01.412812 151265 scheduler.cpp:861] fake:fake_0:1:224x224:163 estimate rps: 2.76588 (last: 2.76588, mean: 6.08962, std: 2.50543), throughput: 6.22279
I1211 06:24:01.413132 151265 scheduler.cpp:1120] Total used GPUs: 1
Backend 503253232: 0.0011679
I1211 06:24:01.413151 151265 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:163: 503253232/6.22279/1, total share: 1
I1211 06:24:11.414000 151265 scheduler.cpp:832] Epoch schedule
I1211 06:24:11.414060 151265 scheduler.cpp:861] fake:fake_0:1:224x224:163 estimate rps: 4.91247 (last: 4.91247, mean: 4.47073, std: 1.49), throughput: 6.22279
I1211 06:24:11.414439 151265 scheduler.cpp:1120] Total used GPUs: 1
Backend 503253232: 0.0011679
I1211 06:24:11.414458 151265 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:163: 503253232/6.22279/1, total share: 1
I1211 06:24:14.591002 151272 scheduler.cpp:115] Unregister BACKEND_NODE 503253232
I1211 06:24:14.591084 151272 scheduler.cpp:454] Remove backend 503253232
I1211 06:24:14.591114 151272 scheduler.cpp:984] fake:fake_0:1:224x224:163 has unassigned workload 6.22279
I1211 06:24:14.591121 151270 scheduler.cpp:115] Unregister FRONTEND_NODE 2932558800
I1211 06:24:14.591146 151272 scheduler.cpp:1007] Unassigned workload fake:fake_0:1:224x224:163, 6.22279 req/s
