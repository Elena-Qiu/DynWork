I1211 09:52:32.143719 160266 rpc_service_base.h:46] RPC service is listening on 0.0.0.0:10001
I1211 09:52:34.710047 160271 scheduler.cpp:98] Register server: node_type: BACKEND_NODE
node_id: 369610182
server_port: "8001"
rpc_port: "8002"
gpu_device_name: "Tesla_V100S-PCIE-32GB"
gpu_available_memory: 33650376704
gpu_uuid: "fcf0dc04-2c7f-7570-499b-47b29c6d534c"
I1211 09:52:36.159168 160273 scheduler.cpp:98] Register server: node_id: 3542574715
server_port: "9001"
rpc_port: "9002"
I1211 09:52:36.159689 160272 model_db.cpp:283] Load model DB from /workdir/models/db/model_db.yml
I1211 09:52:36.160491 160272 backend_delegate.cpp:183] Backend 369610182 loads fake:fake_0:1:224x224:467, batch 8, max batch 8, max duty cycle 2088.45 us, throughput 3830.6 req/s. Backend exec cycle 2088.45 us, duty cycle: 2088.45 us
I1211 09:53:03.147460 160266 scheduler.cpp:832] Epoch schedule
I1211 09:53:03.147567 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 1
I1211 09:53:03.147585 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/3830.6/1, total share: 1
I1211 09:53:18.148824 160266 scheduler.cpp:832] Epoch schedule
I1211 09:53:18.148874 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 4.72657 (last: 4.72657, mean: 3.27798, std: 1.45679), throughput: 3830.6
I1211 09:53:18.148905 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 3, max batch 8, new throughput 6.4695
I1211 09:53:18.150336 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00252958
I1211 09:53:18.150367 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/6.4695/1, total share: 1
I1211 09:53:28.151327 160266 scheduler.cpp:832] Epoch schedule
I1211 09:53:28.151355 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 2.66132 (last: 2.66132, mean: 3.90078, std: 0.91929), throughput: 6.4695
I1211 09:53:28.151377 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 2, max batch 8, new throughput 4.3113
I1211 09:53:28.151897 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:53:28.151917 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:53:38.153018 160266 scheduler.cpp:832] Epoch schedule
I1211 09:53:38.153126 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 1.42865 (last: 1.42865, mean: 3.25952, std: 1.20697), throughput: 4.3113
I1211 09:53:38.153162 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 1, max batch 8, new throughput 2.1548
I1211 09:53:38.154037 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00173855
I1211 09:53:38.154057 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/2.1548/1, total share: 1
I1211 09:53:48.154886 160266 scheduler.cpp:832] Epoch schedule
I1211 09:53:48.155752 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 2.69503 (last: 2.69503, mean: 2.46004, std: 0.839227), throughput: 2.1548
I1211 09:53:48.155778 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 2, max batch 8, new throughput 4.3113
I1211 09:53:48.156407 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:53:48.156427 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:53:59.157223 160266 scheduler.cpp:832] Epoch schedule
I1211 09:53:59.157302 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 3.4471 (last: 3.4471, mean: 2.33267, std: 0.707558), throughput: 4.3113
I1211 09:53:59.157968 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:53:59.157986 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:54:11.158839 160266 scheduler.cpp:832] Epoch schedule
I1211 09:54:11.158910 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 5.21367 (last: 5.21367, mean: 3.02611, std: 0.826092), throughput: 4.3113
I1211 09:54:11.158936 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 3, max batch 8, new throughput 6.4695
I1211 09:54:11.159518 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00252958
I1211 09:54:11.159536 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/6.4695/1, total share: 1
I1211 09:54:21.160320 160266 scheduler.cpp:832] Epoch schedule
I1211 09:54:21.160358 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 4.51712 (last: 4.51712, mean: 4.06291, std: 1.13467), throughput: 6.4695
I1211 09:54:21.160784 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00252958
I1211 09:54:21.160802 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/6.4695/1, total share: 1
I1211 09:54:31.161552 160266 scheduler.cpp:832] Epoch schedule
I1211 09:54:31.161589 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 3.64981 (last: 3.64981, mean: 4.28265, std: 0.946608), throughput: 6.4695
I1211 09:54:31.161609 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 2, max batch 8, new throughput 4.3113
I1211 09:54:31.162199 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:54:31.162230 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:54:53.164016 160266 scheduler.cpp:832] Epoch schedule
I1211 09:54:53.164098 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 3.43388 (last: 3.43388, mean: 3.79969, std: 0.226688), throughput: 4.3113
I1211 09:54:53.164572 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:54:53.164589 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:55:03.165480 160266 scheduler.cpp:832] Epoch schedule
I1211 09:55:03.165522 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 2.5804 (last: 2.5804, mean: 3.6004, std: 0.417592), throughput: 4.3113
I1211 09:55:03.165885 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:55:03.165904 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:55:13.166765 160266 scheduler.cpp:832] Epoch schedule
I1211 09:55:13.166796 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 2.22133 (last: 2.22133, mean: 3.1488, std: 0.619973), throughput: 4.3113
I1211 09:55:13.167120 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:55:13.167138 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:55:23.168064 160266 scheduler.cpp:832] Epoch schedule
I1211 09:55:23.168133 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 2.16921 (last: 2.16921, mean: 2.58796, std: 0.449649), throughput: 4.3113
I1211 09:55:23.168529 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:55:23.168547 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:55:33.169447 160266 scheduler.cpp:832] Epoch schedule
I1211 09:55:33.169494 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 1.77575 (last: 1.77575, mean: 2.17411, std: 0.26904), throughput: 4.3113
I1211 09:55:33.169534 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 1, max batch 8, new throughput 2.1548
I1211 09:55:33.170169 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00173855
I1211 09:55:33.170202 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/2.1548/1, total share: 1
I1211 09:55:43.171054 160266 scheduler.cpp:832] Epoch schedule
I1211 09:55:43.171103 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 3.78375 (last: 3.78375, mean: 2.29078, std: 0.538154), throughput: 2.1548
I1211 09:55:43.171157 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 2, max batch 8, new throughput 4.3113
I1211 09:55:43.171854 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:55:43.171885 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:55:53.172746 160266 scheduler.cpp:832] Epoch schedule
I1211 09:55:53.172791 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 1.84157 (last: 1.84157, mean: 2.39149, std: 0.601902), throughput: 4.3113
I1211 09:55:53.172812 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 1, max batch 8, new throughput 2.1548
I1211 09:55:53.173331 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00173855
I1211 09:55:53.173349 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/2.1548/1, total share: 1
I1211 09:56:03.174132 160266 scheduler.cpp:832] Epoch schedule
I1211 09:56:03.174160 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 3.03047 (last: 3.03047, mean: 2.4519, std: 0.620075), throughput: 2.1548
I1211 09:56:03.174185 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 2, max batch 8, new throughput 4.3113
I1211 09:56:03.174868 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:56:03.174887 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:56:13.175765 160266 scheduler.cpp:832] Epoch schedule
I1211 09:56:13.175820 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 2.21063 (last: 2.21063, mean: 2.42367, std: 0.541751), throughput: 4.3113
I1211 09:56:13.176223 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:56:13.176252 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:56:26.177299 160266 scheduler.cpp:832] Epoch schedule
I1211 09:56:26.177335 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 3.42075 (last: 3.42075, mean: 2.65388, std: 0.685486), throughput: 4.3113
I1211 09:56:26.177769 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:56:26.177788 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:56:36.178838 160266 scheduler.cpp:832] Epoch schedule
I1211 09:56:36.178889 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 2.33352 (last: 2.33352, mean: 2.84426, std: 0.663312), throughput: 4.3113
I1211 09:56:36.179235 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:56:36.179253 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:56:48.180248 160266 scheduler.cpp:832] Epoch schedule
I1211 09:56:48.180285 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 4.93082 (last: 4.93082, mean: 2.99702, std: 0.771198), throughput: 4.3113
I1211 09:56:48.180318 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 3, max batch 8, new throughput 6.4695
I1211 09:56:48.181061 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00252958
I1211 09:56:48.181085 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/6.4695/1, total share: 1
I1211 09:56:58.181951 160266 scheduler.cpp:832] Epoch schedule
I1211 09:56:58.182014 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 3.48703 (last: 3.48703, mean: 3.48435, std: 1.20817), throughput: 6.4695
I1211 09:56:58.182039 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 2, max batch 8, new throughput 4.3113
I1211 09:56:58.182756 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:56:58.182785 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:57:08.183657 160266 scheduler.cpp:832] Epoch schedule
I1211 09:57:08.183698 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 2.11462 (last: 2.11462, mean: 3.49255, std: 1.2025), throughput: 4.3113
I1211 09:57:08.183734 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 1, max batch 8, new throughput 2.1548
I1211 09:57:08.184413 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00173855
I1211 09:57:08.184433 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/2.1548/1, total share: 1
I1211 09:57:18.185215 160266 scheduler.cpp:832] Epoch schedule
I1211 09:57:18.185276 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 3.94852 (last: 3.94852, mean: 3.43521, std: 1.19276), throughput: 2.1548
I1211 09:57:18.185304 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 2, max batch 8, new throughput 4.3113
I1211 09:57:18.185935 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:57:18.185959 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:57:28.186774 160266 scheduler.cpp:832] Epoch schedule
I1211 09:57:28.186851 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 5.23438 (last: 5.23438, mean: 3.07726, std: 0.832855), throughput: 4.3113
I1211 09:57:28.186889 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 3, max batch 8, new throughput 6.4695
I1211 09:57:28.187505 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00252958
I1211 09:57:28.187530 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/6.4695/1, total share: 1
I1211 09:57:38.188388 160266 scheduler.cpp:832] Epoch schedule
I1211 09:57:38.188441 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 2.47666 (last: 2.47666, mean: 3.37223, std: 0.965463), throughput: 6.4695
I1211 09:57:38.188478 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 2, max batch 8, new throughput 4.3113
I1211 09:57:38.189353 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:57:38.189376 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:57:48.190172 160266 scheduler.cpp:832] Epoch schedule
I1211 09:57:48.190193 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 1.64754 (last: 1.64754, mean: 3.1262, std: 1.12181), throughput: 4.3113
I1211 09:57:48.190215 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 1, max batch 8, new throughput 2.1548
I1211 09:57:48.190726 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00173855
I1211 09:57:48.190747 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/2.1548/1, total share: 1
I1211 09:57:58.191531 160266 scheduler.cpp:832] Epoch schedule
I1211 09:57:58.191570 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 0.884698 (last: 0.884698, mean: 2.31473, std: 1.20588), throughput: 2.1548
I1211 09:57:58.191934 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00173855
I1211 09:57:58.191953 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/2.1548/1, total share: 1
I1211 09:58:08.192734 160266 scheduler.cpp:832] Epoch schedule
I1211 09:58:08.192759 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 0.599016 (last: 0.599016, mean: 1.29463, std: 0.552408), throughput: 2.1548
I1211 09:58:08.193068 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00173855
I1211 09:58:08.193086 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/2.1548/1, total share: 1
I1211 09:58:18.193856 160266 scheduler.cpp:832] Epoch schedule
I1211 09:58:18.193890 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 0.941778 (last: 0.941778, mean: 0.887689, std: 0.331517), throughput: 2.1548
I1211 09:58:18.194330 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00173855
I1211 09:58:18.194350 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/2.1548/1, total share: 1
I1211 09:58:28.195124 160266 scheduler.cpp:832] Epoch schedule
I1211 09:58:28.195161 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 0.698707 (last: 0.698707, mean: 0.713855, std: 0.144125), throughput: 2.1548
I1211 09:58:28.195477 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00173855
I1211 09:58:28.195494 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/2.1548/1, total share: 1
I1211 09:58:38.196204 160266 scheduler.cpp:832] Epoch schedule
I1211 09:58:38.196245 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 1.48167 (last: 1.48167, mean: 0.81979, std: 0.240286), throughput: 2.1548
I1211 09:58:38.196666 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00173855
I1211 09:58:38.196697 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/2.1548/1, total share: 1
I1211 09:58:48.197453 160266 scheduler.cpp:832] Epoch schedule
I1211 09:58:48.197479 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 2.4799 (last: 2.4799, mean: 1.21226, std: 0.538667), throughput: 2.1548
I1211 09:58:48.197502 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 2, max batch 8, new throughput 4.3113
I1211 09:58:48.198041 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00213391
I1211 09:58:48.198062 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/4.3113/1, total share: 1
I1211 09:58:58.199079 160266 scheduler.cpp:832] Epoch schedule
I1211 09:58:58.199110 160266 scheduler.cpp:861] fake:fake_0:1:224x224:467 estimate rps: 1.6812 (last: 1.6812, mean: 1.69975, std: 0.566407), throughput: 4.3113
I1211 09:58:58.199131 160266 backend_delegate.cpp:341] Backend 369610182 updates fake:fake_0:1:224x224:467, batch 1, max batch 8, new throughput 2.1548
I1211 09:58:58.199602 160266 scheduler.cpp:1120] Total used GPUs: 1
Backend 369610182: 0.00173855
I1211 09:58:58.199621 160266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:467: 369610182/2.1548/1, total share: 1
*** Aborted at 1639216748 (unix time) try "date -d @1639216748" if you are using GNU date ***
I1211 09:59:08.998613 160274 scheduler.cpp:115] Unregister BACKEND_NODE 369610182
I1211 09:59:08.998647 160274 scheduler.cpp:454] Remove backend 369610182
I1211 09:59:08.998667 160273 scheduler.cpp:115] Unregister FRONTEND_NODE 3542574715
I1211 09:59:08.998673 160274 scheduler.cpp:984] fake:fake_0:1:224x224:467 has unassigned workload 2.1548
I1211 09:59:08.998706 160274 scheduler.cpp:1007] Unassigned workload fake:fake_0:1:224x224:467, 2.1548 req/s
PC: @                0x0 (unknown)
*** SIGTERM (@0x271c8) received by PID 160266 (TID 0x7f022505cf00) from PID 160200; stack trace: ***
    @     0x7f0223d5b980 (unknown)
    @     0x7f0223d5ad50 __GI___nanosleep
    @     0x5610416bcf0d std::this_thread::sleep_for<>()
    @     0x5610416a0269 nexus::scheduler::Scheduler::Run()
    @     0x5610416ef781 main
    @     0x7f021efd0bf7 __libc_start_main
    @     0x56104166beaa _start
    @                0x0 (unknown)
