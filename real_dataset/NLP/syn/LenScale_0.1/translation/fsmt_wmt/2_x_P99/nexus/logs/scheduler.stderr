I1211 10:12:32.393965 161766 rpc_service_base.h:46] RPC service is listening on 0.0.0.0:10001
I1211 10:12:34.958153 161771 scheduler.cpp:98] Register server: node_type: BACKEND_NODE
node_id: 1590268288
server_port: "8001"
rpc_port: "8002"
gpu_device_name: "Tesla_V100S-PCIE-32GB"
gpu_available_memory: 33650376704
gpu_uuid: "fcf0dc04-2c7f-7570-499b-47b29c6d534c"
I1211 10:12:36.410976 161774 scheduler.cpp:98] Register server: node_id: 8439540
server_port: "9001"
rpc_port: "9002"
I1211 10:12:36.411494 161772 model_db.cpp:283] Load model DB from /workdir/models/db/model_db.yml
I1211 10:12:36.412297 161772 backend_delegate.cpp:183] Backend 1590268288 loads fake:fake_0:1:224x224:935, batch 8, max batch 8, max duty cycle 2088.45 us, throughput 3830.6 req/s. Backend exec cycle 2088.45 us, duty cycle: 2088.45 us
I1211 10:13:03.397541 161766 scheduler.cpp:832] Epoch schedule
I1211 10:13:03.397655 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 1
I1211 10:13:03.397675 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/3830.6/1, total share: 1
I1211 10:13:18.398742 161766 scheduler.cpp:832] Epoch schedule
I1211 10:13:18.398802 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 4.72657 (last: 4.72657, mean: 3.26991, std: 1.45141), throughput: 3830.6
I1211 10:13:18.398833 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 5, max batch 8, new throughput 5.36856
I1211 10:13:18.400373 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00165264
I1211 10:13:18.400393 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/5.36856/1, total share: 1
I1211 10:13:28.401144 161766 scheduler.cpp:832] Epoch schedule
I1211 10:13:28.401167 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 2.66132 (last: 2.66132, mean: 3.89271, std: 0.916427), throughput: 5.36856
I1211 10:13:28.401190 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 3, max batch 8, new throughput 3.21987
I1211 10:13:28.401866 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00125897
I1211 10:13:28.401886 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/3.21987/1, total share: 1
I1211 10:13:38.402922 161766 scheduler.cpp:832] Epoch schedule
I1211 10:13:38.402987 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 1.42865 (last: 1.42865, mean: 3.25952, std: 1.20697), throughput: 3.21987
I1211 10:13:38.403009 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 2, max batch 8, new throughput 2.14616
I1211 10:13:38.403649 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00106226
I1211 10:13:38.403673 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/2.14616/1, total share: 1
I1211 10:13:48.404532 161766 scheduler.cpp:832] Epoch schedule
I1211 10:13:48.404561 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 2.69503 (last: 2.69503, mean: 2.46004, std: 0.839227), throughput: 2.14616
I1211 10:13:48.404593 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 3, max batch 8, new throughput 3.21987
I1211 10:13:48.405154 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00125897
I1211 10:13:48.405182 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/3.21987/1, total share: 1
I1211 10:13:58.406087 161766 scheduler.cpp:832] Epoch schedule
I1211 10:13:58.406142 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 3.88372 (last: 3.88372, mean: 2.29356, std: 0.675536), throughput: 3.21987
I1211 10:13:58.406167 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 4, max batch 8, new throughput 4.29401
I1211 10:13:58.406999 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00145577
I1211 10:13:58.407020 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/4.29401/1, total share: 1
I1211 10:14:11.408111 161766 scheduler.cpp:832] Epoch schedule
I1211 10:14:11.408167 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 5.21367 (last: 5.21367, mean: 3.02611, std: 0.826092), throughput: 4.29401
I1211 10:14:11.408195 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 5, max batch 8, new throughput 5.36856
I1211 10:14:11.408921 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00165264
I1211 10:14:11.408946 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/5.36856/1, total share: 1
I1211 10:14:23.409973 161766 scheduler.cpp:832] Epoch schedule
I1211 10:14:23.410020 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 4.06085 (last: 4.06085, mean: 4.19169, std: 1.03766), throughput: 5.36856
I1211 10:14:23.410043 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 4, max batch 8, new throughput 4.29401
I1211 10:14:23.410874 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00145577
I1211 10:14:23.410900 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/4.29401/1, total share: 1
I1211 10:14:53.413380 161766 scheduler.cpp:832] Epoch schedule
I1211 10:14:53.413441 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 3.43388 (last: 3.43388, mean: 3.79969, std: 0.226688), throughput: 4.29401
I1211 10:14:53.413863 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00145577
I1211 10:14:53.413884 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/4.29401/1, total share: 1
I1211 10:15:03.414600 161766 scheduler.cpp:832] Epoch schedule
I1211 10:15:03.414646 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 2.5804 (last: 2.5804, mean: 3.6004, std: 0.417592), throughput: 4.29401
I1211 10:15:03.414669 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 3, max batch 8, new throughput 3.21987
I1211 10:15:03.415309 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00125897
I1211 10:15:03.415330 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/3.21987/1, total share: 1
I1211 10:15:13.416256 161766 scheduler.cpp:832] Epoch schedule
I1211 10:15:13.416299 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 2.22133 (last: 2.22133, mean: 3.1488, std: 0.619973), throughput: 3.21987
I1211 10:15:13.416836 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00125897
I1211 10:15:13.416857 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/3.21987/1, total share: 1
I1211 10:15:23.417660 161766 scheduler.cpp:832] Epoch schedule
I1211 10:15:23.417726 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 2.16921 (last: 2.16921, mean: 2.58796, std: 0.449649), throughput: 3.21987
I1211 10:15:23.418298 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00125897
I1211 10:15:23.418340 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/3.21987/1, total share: 1
I1211 10:15:33.419369 161766 scheduler.cpp:832] Epoch schedule
I1211 10:15:33.419396 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 1.77575 (last: 1.77575, mean: 2.17411, std: 0.26904), throughput: 3.21987
I1211 10:15:33.419418 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 2, max batch 8, new throughput 2.14616
I1211 10:15:33.420109 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00106226
I1211 10:15:33.420135 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/2.14616/1, total share: 1
I1211 10:15:43.421026 161766 scheduler.cpp:832] Epoch schedule
I1211 10:15:43.421077 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 3.78375 (last: 3.78375, mean: 2.29078, std: 0.538154), throughput: 2.14616
I1211 10:15:43.421114 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 4, max batch 8, new throughput 4.29401
I1211 10:15:43.421811 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00145577
I1211 10:15:43.421831 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/4.29401/1, total share: 1
I1211 10:15:53.422966 161766 scheduler.cpp:832] Epoch schedule
I1211 10:15:53.423003 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 1.84157 (last: 1.84157, mean: 2.45623, std: 0.64371), throughput: 4.29401
I1211 10:15:53.423030 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 2, max batch 8, new throughput 2.14616
I1211 10:15:53.423568 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00106226
I1211 10:15:53.423588 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/2.14616/1, total share: 1
I1211 10:16:03.424366 161766 scheduler.cpp:832] Epoch schedule
I1211 10:16:03.424427 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 3.03047 (last: 3.03047, mean: 2.47701, std: 0.65838), throughput: 2.14616
I1211 10:16:03.424465 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 3, max batch 8, new throughput 3.21987
I1211 10:16:03.425180 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00125897
I1211 10:16:03.425201 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/3.21987/1, total share: 1
I1211 10:16:13.426224 161766 scheduler.cpp:832] Epoch schedule
I1211 10:16:13.426259 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 2.21063 (last: 2.21063, mean: 2.44878, std: 0.586458), throughput: 3.21987
I1211 10:16:13.426731 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00125897
I1211 10:16:13.426756 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/3.21987/1, total share: 1
I1211 10:16:23.427601 161766 scheduler.cpp:832] Epoch schedule
I1211 10:16:23.427656 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 4.1195 (last: 4.1195, mean: 2.41942, std: 0.653952), throughput: 3.21987
I1211 10:16:23.427698 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 4, max batch 8, new throughput 4.29401
I1211 10:16:23.428632 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00145577
I1211 10:16:23.428658 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/4.29401/1, total share: 1
I1211 10:16:33.429399 161766 scheduler.cpp:832] Epoch schedule
I1211 10:16:33.429443 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 2.98938 (last: 2.98938, mean: 2.91234, std: 0.662028), throughput: 4.29401
I1211 10:16:33.429466 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 3, max batch 8, new throughput 3.21987
I1211 10:16:33.430109 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00125897
I1211 10:16:33.430135 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/3.21987/1, total share: 1
I1211 10:16:43.430862 161766 scheduler.cpp:832] Epoch schedule
I1211 10:16:43.430899 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 2.12532 (last: 2.12532, mean: 2.76732, std: 0.703497), throughput: 3.21987
I1211 10:16:43.430939 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 2, max batch 8, new throughput 2.14616
I1211 10:16:43.431634 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00106226
I1211 10:16:43.431654 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/2.14616/1, total share: 1
I1211 10:16:53.432588 161766 scheduler.cpp:832] Epoch schedule
I1211 10:16:53.432641 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 5.21631 (last: 5.21631, mean: 3.41143, std: 1.17609), throughput: 2.14616
I1211 10:16:53.432663 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 5, max batch 8, new throughput 5.36856
I1211 10:16:53.433240 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00165264
I1211 10:16:53.433260 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/5.36856/1, total share: 1
I1211 10:17:03.434221 161766 scheduler.cpp:832] Epoch schedule
I1211 10:17:03.434248 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 3.13614 (last: 3.13614, mean: 3.49084, std: 1.2032), throughput: 5.36856
I1211 10:17:03.434271 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 3, max batch 8, new throughput 3.21987
I1211 10:17:03.434918 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00125897
I1211 10:17:03.434943 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/3.21987/1, total share: 1
I1211 10:17:13.436127 161766 scheduler.cpp:832] Epoch schedule
I1211 10:17:13.436175 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 2.1278 (last: 2.1278, mean: 3.47427, std: 1.22487), throughput: 3.21987
I1211 10:17:13.436197 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 2, max batch 8, new throughput 2.14616
I1211 10:17:13.437005 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00106226
I1211 10:17:13.437044 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/2.14616/1, total share: 1
I1211 10:17:23.437944 161766 scheduler.cpp:832] Epoch schedule
I1211 10:17:23.438009 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 3.06863 (last: 3.06863, mean: 3.08502, std: 0.741166), throughput: 2.14616
I1211 10:17:23.438046 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 3, max batch 8, new throughput 3.21987
I1211 10:17:23.438764 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00125897
I1211 10:17:23.438789 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/3.21987/1, total share: 1
I1211 10:17:33.439777 161766 scheduler.cpp:832] Epoch schedule
I1211 10:17:33.439824 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 3.97208 (last: 3.97208, mean: 3.28326, std: 1.02355), throughput: 3.21987
I1211 10:17:33.439847 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 4, max batch 8, new throughput 4.29401
I1211 10:17:33.440425 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00145577
I1211 10:17:33.440446 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/4.29401/1, total share: 1
I1211 10:17:43.441684 161766 scheduler.cpp:832] Epoch schedule
I1211 10:17:43.441718 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 1.91498 (last: 1.91498, mean: 3.38906, std: 0.954919), throughput: 4.29401
I1211 10:17:43.441748 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 2, max batch 8, new throughput 2.14616
I1211 10:17:43.442344 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00106226
I1211 10:17:43.442374 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/2.14616/1, total share: 1
I1211 10:17:53.443675 161766 scheduler.cpp:832] Epoch schedule
I1211 10:17:53.443928 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 1.34002 (last: 1.34002, mean: 2.81381, std: 1.26642), throughput: 2.14616
I1211 10:17:53.444360 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00106226
I1211 10:17:53.444383 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/2.14616/1, total share: 1
I1211 10:18:03.445660 161766 scheduler.cpp:832] Epoch schedule
I1211 10:18:03.445736 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 0.671357 (last: 0.671357, mean: 1.69222, std: 0.762875), throughput: 2.14616
I1211 10:18:03.445782 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 1, max batch 8, new throughput 1.07287
I1211 10:18:03.446866 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00086562
I1211 10:18:03.446889 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/1.07287/1, total share: 1
I1211 10:18:13.448030 161766 scheduler.cpp:832] Epoch schedule
I1211 10:18:13.448077 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 0.574759 (last: 0.574759, mean: 1.04188, std: 0.453446), throughput: 1.07287
I1211 10:18:13.448447 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00086562
I1211 10:18:13.448467 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/1.07287/1, total share: 1
I1211 10:18:23.449800 161766 scheduler.cpp:832] Epoch schedule
I1211 10:18:23.449859 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 0.709261 (last: 0.709261, mean: 0.778243, std: 0.193404), throughput: 1.07287
I1211 10:18:23.450345 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00086562
I1211 10:18:23.450392 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/1.07287/1, total share: 1
I1211 10:18:36.451833 161766 scheduler.cpp:832] Epoch schedule
I1211 10:18:36.451881 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 1.25069 (last: 1.25069, mean: 0.769281, std: 0.191539), throughput: 1.07287
I1211 10:18:36.451905 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 2, max batch 8, new throughput 2.14616
I1211 10:18:36.452636 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00106226
I1211 10:18:36.452661 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/2.14616/1, total share: 1
I1211 10:18:48.453827 161766 scheduler.cpp:832] Epoch schedule
I1211 10:18:48.453852 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 2.4799 (last: 2.4799, mean: 1.21228, std: 0.538652), throughput: 2.14616
I1211 10:18:48.453878 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 3, max batch 8, new throughput 3.21987
I1211 10:18:48.454530 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00125897
I1211 10:18:48.454555 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/3.21987/1, total share: 1
I1211 10:18:58.455657 161766 scheduler.cpp:832] Epoch schedule
I1211 10:18:58.455739 161766 scheduler.cpp:861] fake:fake_0:1:224x224:935 estimate rps: 1.68121 (last: 1.68121, mean: 1.69976, std: 0.5664), throughput: 3.21987
I1211 10:18:58.455776 161766 backend_delegate.cpp:341] Backend 1590268288 updates fake:fake_0:1:224x224:935, batch 2, max batch 8, new throughput 2.14616
I1211 10:18:58.456482 161766 scheduler.cpp:1120] Total used GPUs: 1
Backend 1590268288: 0.00106226
I1211 10:18:58.456503 161766 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:935: 1590268288/2.14616/1, total share: 1
*** Aborted at 1639217949 (unix time) try "date -d @1639217949" if you are using GNU date ***
I1211 10:19:09.257860 161771 scheduler.cpp:115] Unregister FRONTEND_NODE 8439540
I1211 10:19:09.257894 161774 scheduler.cpp:115] Unregister BACKEND_NODE 1590268288
I1211 10:19:09.257898 161771 scheduler.cpp:442] Remove frontend 8439540
I1211 10:19:09.257974 161771 scheduler.cpp:656] Remove model session: fake:fake_0:1:224x224:935
I1211 10:19:09.257982 161771 backend_delegate.cpp:290] Backend 1590268288 unload model: fake:fake_0:1:224x224:935
PC: @                0x0 (unknown)
*** SIGTERM (@0x277a4) received by PID 161766 (TID 0x7f6cb4c31f00) from PID 161700; stack trace: ***
I1211 10:19:09.258649 161774 scheduler.cpp:454] Remove backend 1590268288
    @     0x7f6cb3930980 (unknown)
    @     0x7f6cb392fd50 __GI___nanosleep
    @     0x5599e5ee1f0d std::this_thread::sleep_for<>()
    @     0x5599e5ec5269 nexus::scheduler::Scheduler::Run()
    @     0x5599e5f14781 main
    @     0x7f6caeba5bf7 __libc_start_main
    @     0x5599e5e90eaa _start
    @                0x0 (unknown)
