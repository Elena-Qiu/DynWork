I1211 00:02:16.155401 84291 rpc_service_base.h:46] RPC service is listening on 0.0.0.0:10001
I1211 00:02:18.714279 84296 scheduler.cpp:98] Register server: node_type: BACKEND_NODE
node_id: 1020541550
server_port: "8001"
rpc_port: "8002"
gpu_device_name: "Tesla_V100S-PCIE-32GB"
gpu_available_memory: 33650376704
gpu_uuid: "fcf0dc04-2c7f-7570-499b-47b29c6d534c"
I1211 00:02:20.171579 84299 scheduler.cpp:98] Register server: node_id: 4117544463
server_port: "9001"
rpc_port: "9002"
I1211 00:02:20.172047 84298 model_db.cpp:283] Load model DB from /workdir/models/db/model_db.yml
I1211 00:02:20.172895 84298 backend_delegate.cpp:183] Backend 1020541550 loads fake:fake_0:1:224x224:849, batch 8, max batch 8, max duty cycle 1173.87 us, throughput 6815.07 req/s. Backend exec cycle 1173.87 us, duty cycle: 1173.87 us
I1211 00:02:47.159050 84291 scheduler.cpp:832] Epoch schedule
I1211 00:02:47.159150 84291 scheduler.cpp:1120] Total used GPUs: 1
Backend 1020541550: 1
I1211 00:02:47.159170 84291 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:849: 1020541550/6815.07/1, total share: 1
I1211 00:03:02.160569 84291 scheduler.cpp:832] Epoch schedule
I1211 00:03:02.160609 84291 scheduler.cpp:861] fake:fake_0:1:224x224:849 estimate rps: 1.67229 (last: 1.67229, mean: 1.27392, std: 0.429368), throughput: 6815.07
I1211 00:03:02.160646 84291 backend_delegate.cpp:341] Backend 1020541550 updates fake:fake_0:1:224x224:849, batch 2, max batch 8, new throughput 2.3644
I1211 00:03:02.161936 84291 scheduler.cpp:1120] Total used GPUs: 1
Backend 1020541550: 0.00118813
I1211 00:03:02.161957 84291 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:849: 1020541550/2.3644/1, total share: 1
I1211 00:03:12.162916 84291 scheduler.cpp:832] Epoch schedule
I1211 00:03:12.162956 84291 scheduler.cpp:861] fake:fake_0:1:224x224:849 estimate rps: 1.81565 (last: 1.81565, mean: 1.61068, std: 0.173946), throughput: 2.3644
I1211 00:03:12.163530 84291 scheduler.cpp:1120] Total used GPUs: 1
Backend 1020541550: 0.00118813
I1211 00:03:12.163550 84291 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:849: 1020541550/2.3644/1, total share: 1
I1211 00:03:22.164430 84291 scheduler.cpp:832] Epoch schedule
I1211 00:03:22.164502 84291 scheduler.cpp:861] fake:fake_0:1:224x224:849 estimate rps: 1.82299 (last: 1.82299, mean: 1.7452, std: 0.0670403), throughput: 2.3644
I1211 00:03:22.165078 84291 scheduler.cpp:1120] Total used GPUs: 1
Backend 1020541550: 0.00118813
I1211 00:03:22.165110 84291 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:849: 1020541550/2.3644/1, total share: 1
I1211 00:03:32.165916 84291 scheduler.cpp:832] Epoch schedule
I1211 00:03:32.165952 84291 scheduler.cpp:861] fake:fake_0:1:224x224:849 estimate rps: 5.5978 (last: 5.5978, mean: 2.42465, std: 1.18714), throughput: 2.3644
I1211 00:03:32.165988 84291 backend_delegate.cpp:341] Backend 1020541550 updates fake:fake_0:1:224x224:849, batch 5, max batch 8, new throughput 5.91158
I1211 00:03:32.166913 84291 scheduler.cpp:1120] Total used GPUs: 1
Backend 1020541550: 0.00128807
I1211 00:03:32.166934 84291 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:849: 1020541550/5.91158/1, total share: 1
I1211 00:03:42.167754 84291 scheduler.cpp:832] Epoch schedule
I1211 00:03:42.167795 84291 scheduler.cpp:861] fake:fake_0:1:224x224:849 estimate rps: 9.57724 (last: 9.57724, mean: 4.5329, std: 2.86697), throughput: 5.91158
I1211 00:03:42.167831 84291 backend_delegate.cpp:341] Backend 1020541550 updates fake:fake_0:1:224x224:849, batch 8, max batch 8, new throughput 9.57724
I1211 00:03:42.168694 84291 scheduler.cpp:1120] Total used GPUs: 1
Backend 1020541550: 0.0014053
I1211 00:03:42.168715 84291 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:849: 1020541550/9.57724/1, total share: 1
I1211 00:04:11.170876 84291 scheduler.cpp:832] Epoch schedule
I1211 00:04:11.170931 84291 scheduler.cpp:861] fake:fake_0:1:224x224:849 estimate rps: 7.62675 (last: 7.62675, mean: 9.44234, std: 1.08187), throughput: 9.57724
I1211 00:04:11.170976 84291 backend_delegate.cpp:341] Backend 1020541550 updates fake:fake_0:1:224x224:849, batch 7, max batch 8, new throughput 8.27676
I1211 00:04:11.171885 84291 scheduler.cpp:1120] Total used GPUs: 1
Backend 1020541550: 0.0013547
I1211 00:04:11.171905 84291 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:849: 1020541550/8.27676/1, total share: 1
I1211 00:04:35.173686 84291 scheduler.cpp:832] Epoch schedule
I1211 00:04:35.173755 84291 scheduler.cpp:861] fake:fake_0:1:224x224:849 estimate rps: 9.25665 (last: 9.25665, mean: 7.5517, std: 0.754033), throughput: 8.27676
I1211 00:04:35.173792 84291 backend_delegate.cpp:341] Backend 1020541550 updates fake:fake_0:1:224x224:849, batch 8, max batch 8, new throughput 9.45947
I1211 00:04:35.174553 84291 scheduler.cpp:1120] Total used GPUs: 1
Backend 1020541550: 0.00138802
I1211 00:04:35.174574 84291 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:849: 1020541550/9.45947/1, total share: 1
I1211 00:04:51.175953 84291 scheduler.cpp:832] Epoch schedule
I1211 00:04:51.176060 84291 scheduler.cpp:861] fake:fake_0:1:224x224:849 estimate rps: 7.20574 (last: 7.20574, mean: 8.69951, std: 1.23269), throughput: 9.45947
I1211 00:04:51.176115 84291 backend_delegate.cpp:341] Backend 1020541550 updates fake:fake_0:1:224x224:849, batch 7, max batch 8, new throughput 8.27676
I1211 00:04:51.176942 84291 scheduler.cpp:1120] Total used GPUs: 1
Backend 1020541550: 0.0013547
I1211 00:04:51.176962 84291 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:849: 1020541550/8.27676/1, total share: 1
I1211 00:05:01.177959 84291 scheduler.cpp:832] Epoch schedule
I1211 00:05:01.178020 84291 scheduler.cpp:861] fake:fake_0:1:224x224:849 estimate rps: 3.78992 (last: 3.78992, mean: 7.9949, std: 2.18703), throughput: 8.27676
I1211 00:05:01.178068 84291 backend_delegate.cpp:341] Backend 1020541550 updates fake:fake_0:1:224x224:849, batch 4, max batch 8, new throughput 4.72911
I1211 00:05:01.178879 84291 scheduler.cpp:1120] Total used GPUs: 1
Backend 1020541550: 0.00125475
I1211 00:05:01.178900 84291 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:849: 1020541550/4.72911/1, total share: 1
I1211 00:05:11.179646 84291 scheduler.cpp:832] Epoch schedule
I1211 00:05:11.179716 84291 scheduler.cpp:861] fake:fake_0:1:224x224:849 estimate rps: 2.52014 (last: 2.52014, mean: 5.92448, std: 2.84748), throughput: 4.72911
I1211 00:05:11.179764 84291 backend_delegate.cpp:341] Backend 1020541550 updates fake:fake_0:1:224x224:849, batch 3, max batch 8, new throughput 3.54671
I1211 00:05:11.180531 84291 scheduler.cpp:1120] Total used GPUs: 1
Backend 1020541550: 0.00122144
I1211 00:05:11.180550 84291 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:849: 1020541550/3.54671/1, total share: 1
*** Aborted at 1639181116 (unix time) try "date -d @1639181116" if you are using GNU date ***
I1211 00:05:17.002389 84298 scheduler.cpp:115] Unregister BACKEND_NODE 1020541550
I1211 00:05:17.002436 84298 scheduler.cpp:454] Remove backend 1020541550
I1211 00:05:17.002465 84298 scheduler.cpp:984] fake:fake_0:1:224x224:849 has unassigned workload 3.54671
I1211 00:05:17.002498 84298 scheduler.cpp:1007] Unassigned workload fake:fake_0:1:224x224:849, 3.54671 req/s
I1211 00:05:17.002503 84299 scheduler.cpp:115] Unregister FRONTEND_NODE 4117544463
PC: @                0x0 (unknown)
*** SIGTERM (@0x14901) received by PID 84291 (TID 0x7fbc85fbdf00) from PID 84225; stack trace: ***
    @     0x7fbc84cbc980 (unknown)
    @     0x7fbc84cbbd50 __GI___nanosleep
    @     0x55557ddabf0d std::this_thread::sleep_for<>()
    @     0x55557dd8f269 nexus::scheduler::Scheduler::Run()
    @     0x55557ddde781 main
    @     0x7fbc7ff31bf7 __libc_start_main
    @     0x55557dd5aeaa _start
    @                0x0 (unknown)
