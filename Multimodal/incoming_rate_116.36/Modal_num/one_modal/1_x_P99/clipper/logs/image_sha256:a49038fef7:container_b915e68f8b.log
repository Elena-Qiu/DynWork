Starting Python Closure container
Connecting to Clipper with default port: 7000
/usr/local/lib/python3.7/runpy.py:125: RuntimeWarning: 'clipper_admin.metrics.server' found in sys.modules after import of package 'clipper_admin.metrics', but prior to execution of 'clipper_admin.metrics.server'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
22-02-02:01:18:23 INFO     [server.py:80] Metric Server Started!
22-02-02:01:18:23 INFO     [server.py:85] Redis Connected! Waiting for messages...
Serving predictions for floats input type.
Sent heartbeat!
Received heartbeat!
Sent container metadata!
Got start of message 0 
fake_model: serving batch [[1.]], sleeping for 1.00ms = 0.74 + 0.26 * 1 * 1.00
fake_model: returning [1.0]
recv: 0.000532 s, parse: 0.000011 s, handle: 0.002072 s
Got start of message 1 
fake_model: serving batch [[53.60764]], sleeping for 53.61ms = 39.73 + 0.26 * 1 * 53.61
fake_model: returning [53.60764]
recv: 0.000292 s, parse: 0.000010 s, handle: 0.054208 s
Got start of message 2 
fake_model: serving batch [[49.994244]], sleeping for 49.99ms = 37.05 + 0.26 * 1 * 49.99
fake_model: returning [49.994244]
recv: 0.000061 s, parse: 0.000002 s, handle: 0.050161 s
Got start of message 3 
fake_model: serving batch [[50.45794]
 [70.67738]], sleeping for 88.98ms = 52.38 + 0.26 * 2 * 70.68
fake_model: returning [50.45794, 70.67738]
recv: 0.000069 s, parse: 0.000002 s, handle: 0.089163 s
Got start of message 4 
fake_model: serving batch [[63.580463]
 [56.659626]], sleeping for 80.04ms = 47.12 + 0.26 * 2 * 63.58
fake_model: returning [63.580463, 56.659626]
recv: 0.000074 s, parse: 0.000003 s, handle: 0.080238 s
Got start of message 5 
fake_model: serving batch [[58.02006 ]
 [83.387375]
 [40.11469 ]
 [40.909973]], sleeping for 148.17ms = 61.79 + 0.26 * 4 * 83.39
fake_model: returning [58.02006, 83.387375, 40.11469, 40.909973]
recv: 0.000064 s, parse: 0.000002 s, handle: 0.148361 s
Got start of message 6 
fake_model: serving batch [[73.04116 ]
 [56.801445]
 [62.56789 ]
 [62.888374]
 [50.759205]], sleeping for 148.70ms = 54.13 + 0.26 * 5 * 73.04
fake_model: returning [73.04116, 56.801445, 62.56789, 62.888374, 50.759205]
recv: 0.000074 s, parse: 0.000002 s, handle: 0.148923 s
Got start of message 7 
fake_model: serving batch [[53.74961 ]
 [44.22384 ]
 [46.227577]
 [59.993305]
 [51.17425 ]
 [51.75252 ]
 [52.038094]
 [40.53873 ]], sleeping for 168.74ms = 44.46 + 0.26 * 8 * 59.99
fake_model: returning [53.74961, 44.22384, 46.227577, 59.993305, 51.17425, 51.75252, 52.038094, 40.53873]
recv: 0.000089 s, parse: 0.000003 s, handle: 0.168977 s
Got start of message 8 
fake_model: serving batch [[53.322784]], sleeping for 53.32ms = 39.52 + 0.26 * 1 * 53.32
fake_model: returning [53.322784]
recv: 0.000164 s, parse: 0.000005 s, handle: 0.053673 s
Got start of message 9 
fake_model: serving batch [[66.082634]], sleeping for 66.08ms = 48.97 + 0.26 * 1 * 66.08
fake_model: returning [66.082634]
recv: 0.000059 s, parse: 0.000002 s, handle: 0.066226 s
Got start of message 10 
fake_model: serving batch [[ 65.234924]
 [ 59.155006]
 [100.      ]
 [ 76.87566 ]
 [ 70.36379 ]
 [ 54.27904 ]
 [ 56.140083]
 [ 54.948513]], sleeping for 281.26ms = 74.11 + 0.26 * 8 * 100.00
fake_model: returning [65.234924, 59.155006, 100.0, 76.87566, 70.36379, 54.27904, 56.140083, 54.948513]
recv: 0.000091 s, parse: 0.000002 s, handle: 0.281501 s
Got start of message 11 
fake_model: serving batch [[47.930645]
 [67.83056 ]
 [61.774376]
 [55.87548 ]], sleeping for 120.52ms = 50.27 + 0.26 * 4 * 67.83
fake_model: returning [47.930645, 67.83056, 61.774376, 55.87548]
recv: 0.000079 s, parse: 0.000002 s, handle: 0.120711 s
Got start of message 12 
fake_model: serving batch [[47.562416]], sleeping for 47.56ms = 35.25 + 0.26 * 1 * 47.56
fake_model: returning [47.562416]
recv: 0.000155 s, parse: 0.000005 s, handle: 0.047873 s
