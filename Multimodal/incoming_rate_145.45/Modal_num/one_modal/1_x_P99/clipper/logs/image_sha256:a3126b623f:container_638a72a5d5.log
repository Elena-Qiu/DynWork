Starting Python Closure container
Connecting to Clipper with default port: 7000
/usr/local/lib/python3.7/runpy.py:125: RuntimeWarning: 'clipper_admin.metrics.server' found in sys.modules after import of package 'clipper_admin.metrics', but prior to execution of 'clipper_admin.metrics.server'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
22-02-02:02:29:34 INFO     [server.py:80] Metric Server Started!
22-02-02:02:29:34 INFO     [server.py:85] Redis Connected! Waiting for messages...
Serving predictions for floats input type.
Sent heartbeat!
Received heartbeat!
Sent container metadata!
Got start of message 0 
fake_model: serving batch [[1.]], sleeping for 1.00ms = 0.74 + 0.26 * 1 * 1.00
fake_model: returning [1.0]
recv: 0.000489 s, parse: 0.000010 s, handle: 0.002091 s
Got start of message 1 
fake_model: serving batch [[50.77877]], sleeping for 50.78ms = 37.63 + 0.26 * 1 * 50.78
fake_model: returning [50.77877]
recv: 0.000290 s, parse: 0.000010 s, handle: 0.051377 s
Got start of message 2 
fake_model: serving batch [[36.181637]], sleeping for 36.18ms = 26.81 + 0.26 * 1 * 36.18
fake_model: returning [36.181637]
recv: 0.000069 s, parse: 0.000003 s, handle: 0.036342 s
Got start of message 3 
fake_model: serving batch [[38.230053]
 [69.16807 ]], sleeping for 87.08ms = 51.26 + 0.26 * 2 * 69.17
fake_model: returning [38.230053, 69.16807]
recv: 0.000072 s, parse: 0.000003 s, handle: 0.087273 s
Got start of message 4 
fake_model: serving batch [[59.892582]
 [44.165623]
 [64.45422 ]], sleeping for 97.83ms = 47.76 + 0.26 * 3 * 64.45
fake_model: returning [59.892582, 44.165623, 64.45422]
recv: 0.000078 s, parse: 0.000002 s, handle: 0.098026 s
Got start of message 5 
fake_model: serving batch [[67.318016]
 [39.54613 ]
 [52.39002 ]
 [53.87373 ]
 [60.91041 ]
 [40.718758]], sleeping for 154.48ms = 49.89 + 0.26 * 6 * 67.32
fake_model: returning [67.318016, 39.54613, 52.39002, 53.87373, 60.91041, 40.718758]
recv: 0.000078 s, parse: 0.000002 s, handle: 0.154717 s
Got start of message 6 
fake_model: serving batch [[48.337265]
 [49.064728]
 [50.637142]
 [63.19588 ]
 [44.94673 ]
 [32.820927]
 [36.619957]], sleeping for 161.38ms = 46.83 + 0.26 * 7 * 63.20
fake_model: returning [48.337265, 49.064728, 50.637142, 63.19588, 44.94673, 32.820927, 36.619957]
recv: 0.000078 s, parse: 0.000002 s, handle: 0.161615 s
Got start of message 7 
fake_model: serving batch [[68.8008]], sleeping for 68.80ms = 50.99 + 0.26 * 1 * 68.80
fake_model: returning [68.8008]
recv: 0.000180 s, parse: 0.000007 s, handle: 0.069196 s
Got start of message 8 
fake_model: serving batch [[61.822174]], sleeping for 61.82ms = 45.81 + 0.26 * 1 * 61.82
fake_model: returning [61.822174]
recv: 0.000074 s, parse: 0.000003 s, handle: 0.062008 s
Got start of message 9 
fake_model: serving batch [[62.79103 ]
 [54.42799 ]
 [53.465256]
 [58.12116 ]
 [29.025694]
 [61.075405]
 [62.393833]
 [46.335503]], sleeping for 176.61ms = 46.53 + 0.26 * 8 * 62.79
fake_model: returning [62.79103, 54.42799, 53.465256, 58.12116, 29.025694, 61.075405, 62.393833, 46.335503]
recv: 0.000095 s, parse: 0.000002 s, handle: 0.176855 s
Got start of message 10 
fake_model: serving batch [[33.677975]], sleeping for 33.68ms = 24.96 + 0.26 * 1 * 33.68
fake_model: returning [33.677975]
recv: 0.000154 s, parse: 0.000005 s, handle: 0.033987 s
