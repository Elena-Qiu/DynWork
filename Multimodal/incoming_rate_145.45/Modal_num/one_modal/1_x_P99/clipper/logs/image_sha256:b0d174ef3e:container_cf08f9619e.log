Starting Python Closure container
Connecting to Clipper with default port: 7000
/usr/local/lib/python3.7/runpy.py:125: RuntimeWarning: 'clipper_admin.metrics.server' found in sys.modules after import of package 'clipper_admin.metrics', but prior to execution of 'clipper_admin.metrics.server'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
22-02-02:01:49:09 INFO     [server.py:80] Metric Server Started!
22-02-02:01:49:09 INFO     [server.py:85] Redis Connected! Waiting for messages...
Serving predictions for floats input type.
Sent heartbeat!
Received heartbeat!
Sent container metadata!
Got start of message 0 
fake_model: serving batch [[1.]], sleeping for 1.00ms = 0.74 + 0.26 * 1 * 1.00
fake_model: returning [1.0]
recv: 0.000508 s, parse: 0.000010 s, handle: 0.002074 s
Got start of message 1 
fake_model: serving batch [[50.77877]], sleeping for 50.78ms = 37.63 + 0.26 * 1 * 50.78
fake_model: returning [50.77877]
recv: 0.000291 s, parse: 0.000010 s, handle: 0.051414 s
Got start of message 2 
fake_model: serving batch [[36.181637]], sleeping for 36.18ms = 26.81 + 0.26 * 1 * 36.18
fake_model: returning [36.181637]
recv: 0.000070 s, parse: 0.000002 s, handle: 0.036355 s
Got start of message 3 
fake_model: serving batch [[38.230053]
 [69.16807 ]], sleeping for 87.08ms = 51.26 + 0.26 * 2 * 69.17
fake_model: returning [38.230053, 69.16807]
recv: 0.000074 s, parse: 0.000002 s, handle: 0.087250 s
Got start of message 4 
fake_model: serving batch [[59.892582]
 [44.165623]
 [64.45422 ]], sleeping for 97.83ms = 47.76 + 0.26 * 3 * 64.45
fake_model: returning [59.892582, 44.165623, 64.45422]
recv: 0.000082 s, parse: 0.000003 s, handle: 0.098059 s
Got start of message 5 
fake_model: serving batch [[67.318016]
 [39.54613 ]
 [52.39002 ]
 [53.87373 ]
 [60.91041 ]
 [40.718758]], sleeping for 154.48ms = 49.89 + 0.26 * 6 * 67.32
fake_model: returning [67.318016, 39.54613, 52.39002, 53.87373, 60.91041, 40.718758]
recv: 0.000072 s, parse: 0.000002 s, handle: 0.154693 s
Got start of message 6 
fake_model: serving batch [[48.337265]
 [49.064728]
 [50.637142]
 [63.19588 ]
 [44.94673 ]
 [32.820927]
 [36.619957]], sleeping for 161.38ms = 46.83 + 0.26 * 7 * 63.20
fake_model: returning [48.337265, 49.064728, 50.637142, 63.19588, 44.94673, 32.820927, 36.619957]
recv: 0.000074 s, parse: 0.000002 s, handle: 0.161607 s
Got start of message 7 
fake_model: serving batch [[68.8008]], sleeping for 68.80ms = 50.99 + 0.26 * 1 * 68.80
fake_model: returning [68.8008]
recv: 0.000149 s, parse: 0.000005 s, handle: 0.069097 s
Got start of message 8 
fake_model: serving batch [[54.42799]], sleeping for 54.43ms = 40.33 + 0.26 * 1 * 54.43
fake_model: returning [54.42799]
recv: 0.000058 s, parse: 0.000002 s, handle: 0.054579 s
Got start of message 9 
fake_model: serving batch [[53.465256]
 [58.12116 ]
 [61.822174]
 [62.79103 ]
 [60.53688 ]
 [52.13448 ]
 [68.3911  ]
 [66.69069 ]], sleeping for 192.36ms = 50.68 + 0.26 * 8 * 68.39
fake_model: returning [53.465256, 58.12116, 61.822174, 62.79103, 60.53688, 52.13448, 68.3911, 66.69069]
recv: 0.000079 s, parse: 0.000002 s, handle: 0.192608 s
Got start of message 10 
fake_model: serving batch [[33.677975]], sleeping for 33.68ms = 24.96 + 0.26 * 1 * 33.68
fake_model: returning [33.677975]
recv: 0.000176 s, parse: 0.000005 s, handle: 0.033955 s
