Starting Python Closure container
Connecting to Clipper with default port: 7000
/usr/local/lib/python3.7/runpy.py:125: RuntimeWarning: 'clipper_admin.metrics.server' found in sys.modules after import of package 'clipper_admin.metrics', but prior to execution of 'clipper_admin.metrics.server'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
22-02-02:02:31:22 INFO     [server.py:80] Metric Server Started!
22-02-02:02:31:22 INFO     [server.py:85] Redis Connected! Waiting for messages...
Serving predictions for floats input type.
Sent heartbeat!
Received heartbeat!
Sent container metadata!
Got start of message 0 
fake_model: serving batch [[1.]], sleeping for 1.00ms = 0.74 + 0.26 * 1 * 1.00
fake_model: returning [1.0]
recv: 0.000496 s, parse: 0.000011 s, handle: 0.002112 s
Got start of message 1 
fake_model: serving batch [[50.77877]], sleeping for 50.78ms = 37.63 + 0.26 * 1 * 50.78
fake_model: returning [50.77877]
recv: 0.000323 s, parse: 0.000010 s, handle: 0.051392 s
Got start of message 2 
fake_model: serving batch [[36.181637]], sleeping for 36.18ms = 26.81 + 0.26 * 1 * 36.18
fake_model: returning [36.181637]
recv: 0.000363 s, parse: 0.000014 s, handle: 0.036864 s
Got start of message 3 
fake_model: serving batch [[38.230053]
 [69.16807 ]], sleeping for 87.08ms = 51.26 + 0.26 * 2 * 69.17
fake_model: returning [38.230053, 69.16807]
recv: 0.000198 s, parse: 0.000003 s, handle: 0.087289 s
Got start of message 4 
fake_model: serving batch [[59.892582]
 [44.165623]
 [64.45422 ]], sleeping for 97.83ms = 47.76 + 0.26 * 3 * 64.45
fake_model: returning [59.892582, 44.165623, 64.45422]
recv: 0.000090 s, parse: 0.000003 s, handle: 0.098039 s
Got start of message 5 
fake_model: serving batch [[44.368557]
 [67.318016]
 [39.54613 ]
 [52.39002 ]
 [53.87373 ]
 [60.91041 ]
 [40.718758]], sleeping for 171.91ms = 49.89 + 0.26 * 7 * 67.32
fake_model: returning [44.368557, 67.318016, 39.54613, 52.39002, 53.87373, 60.91041, 40.718758]
recv: 0.000101 s, parse: 0.000003 s, handle: 0.172161 s
Got start of message 6 
fake_model: serving batch [[66.12955 ]
 [43.764687]
 [51.75422 ]
 [65.63664 ]
 [48.337265]
 [49.064728]
 [50.637142]
 [63.19588 ]], sleeping for 186.00ms = 49.01 + 0.26 * 8 * 66.13
fake_model: returning [66.12955, 43.764687, 51.75422, 65.63664, 48.337265, 49.064728, 50.637142, 63.19588]
recv: 0.000259 s, parse: 0.000003 s, handle: 0.186278 s
Got start of message 7 
fake_model: serving batch [[68.8008]], sleeping for 68.80ms = 50.99 + 0.26 * 1 * 68.80
fake_model: returning [68.8008]
recv: 0.000232 s, parse: 0.000003 s, handle: 0.068965 s
Got start of message 8 
fake_model: serving batch [[53.465256]], sleeping for 53.47ms = 39.62 + 0.26 * 1 * 53.47
fake_model: returning [53.465256]
recv: 0.000291 s, parse: 0.000009 s, handle: 0.053788 s
Got start of message 9 
fake_model: serving batch [[62.79103 ]
 [58.83819 ]
 [61.822174]
 [52.923515]
 [41.23078 ]
 [54.42799 ]
 [58.12116 ]
 [68.3911  ]], sleeping for 192.36ms = 50.68 + 0.26 * 8 * 68.39
fake_model: returning [62.79103, 58.83819, 61.822174, 52.923515, 41.23078, 54.42799, 58.12116, 68.3911]
recv: 0.000104 s, parse: 0.000003 s, handle: 0.192624 s
Got start of message 10 
fake_model: serving batch [[55.092113]], sleeping for 55.09ms = 40.83 + 0.26 * 1 * 55.09
fake_model: returning [55.092113]
recv: 0.000268 s, parse: 0.000008 s, handle: 0.055388 s
