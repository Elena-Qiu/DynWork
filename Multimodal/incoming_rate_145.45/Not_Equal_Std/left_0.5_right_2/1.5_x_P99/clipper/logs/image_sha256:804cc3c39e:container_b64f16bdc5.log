Starting Python Closure container
Connecting to Clipper with default port: 7000
/usr/local/lib/python3.7/runpy.py:125: RuntimeWarning: 'clipper_admin.metrics.server' found in sys.modules after import of package 'clipper_admin.metrics', but prior to execution of 'clipper_admin.metrics.server'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
22-02-02:02:47:42 INFO     [server.py:80] Metric Server Started!
22-02-02:02:47:42 INFO     [server.py:85] Redis Connected! Waiting for messages...
Serving predictions for floats input type.
Sent heartbeat!
Received heartbeat!
Sent container metadata!
Got start of message 0 
fake_model: serving batch [[1.]], sleeping for 1.00ms = 0.74 + 0.26 * 1 * 1.00
fake_model: returning [1.0]
recv: 0.000517 s, parse: 0.000010 s, handle: 0.002072 s
Got start of message 1 
fake_model: serving batch [[21.131369]], sleeping for 21.13ms = 15.66 + 0.26 * 1 * 21.13
fake_model: returning [21.131369]
recv: 0.000293 s, parse: 0.000010 s, handle: 0.021738 s
Got start of message 2 
fake_model: serving batch [[61.974216]], sleeping for 61.97ms = 45.93 + 0.26 * 1 * 61.97
fake_model: returning [61.974216]
recv: 0.000062 s, parse: 0.000002 s, handle: 0.062140 s
Got start of message 3 
fake_model: serving batch [[20.484167]
 [62.309963]], sleeping for 78.44ms = 46.18 + 0.26 * 2 * 62.31
fake_model: returning [20.484167, 62.309963]
recv: 0.000071 s, parse: 0.000002 s, handle: 0.078662 s
Got start of message 4 
fake_model: serving batch [[58.72496 ]
 [53.9568  ]
 [28.026802]], sleeping for 89.14ms = 43.52 + 0.26 * 3 * 58.72
fake_model: returning [58.72496, 53.9568, 28.026802]
recv: 0.000086 s, parse: 0.000003 s, handle: 0.089368 s
Got start of message 5 
fake_model: serving batch [[66.706   ]
 [26.111994]
 [19.446115]
 [49.319244]
 [22.72185 ]
 [68.548096]], sleeping for 157.30ms = 50.80 + 0.26 * 6 * 68.55
fake_model: returning [66.706, 26.111994, 19.446115, 49.319244, 22.72185, 68.548096]
recv: 0.000070 s, parse: 0.000002 s, handle: 0.157521 s
Got start of message 6 
fake_model: serving batch [[ 77.23185 ]
 [ 26.912045]
 [ 38.614166]
 [ 25.984257]
 [ 21.557137]
 [ 22.794235]
 [100.      ]
 [ 20.080677]], sleeping for 281.26ms = 74.11 + 0.26 * 8 * 100.00
fake_model: returning [77.23185, 26.912045, 38.614166, 25.984257, 21.557137, 22.794235, 100.0, 20.080677]
recv: 0.000087 s, parse: 0.000002 s, handle: 0.281499 s
Got start of message 7 
fake_model: serving batch [[62.960518]], sleeping for 62.96ms = 46.66 + 0.26 * 1 * 62.96
fake_model: returning [62.960518]
recv: 0.000139 s, parse: 0.000005 s, handle: 0.063241 s
Got start of message 8 
fake_model: serving batch [[55.358337]], sleeping for 55.36ms = 41.02 + 0.26 * 1 * 55.36
fake_model: returning [55.358337]
recv: 0.000089 s, parse: 0.000004 s, handle: 0.055575 s
Got start of message 9 
fake_model: serving batch [[42.646446]
 [73.69327 ]
 [32.307755]
 [20.181051]
 [70.164154]
 [19.584381]
 [44.2377  ]
 [22.435184]], sleeping for 207.27ms = 54.61 + 0.26 * 8 * 73.69
fake_model: returning [42.646446, 73.69327, 32.307755, 20.181051, 70.164154, 19.584381, 44.2377, 22.435184]
recv: 0.000081 s, parse: 0.000002 s, handle: 0.207520 s
Got start of message 10 
fake_model: serving batch [[71.420135]], sleeping for 71.42ms = 52.93 + 0.26 * 1 * 71.42
fake_model: returning [71.420135]
recv: 0.000127 s, parse: 0.000004 s, handle: 0.071671 s
