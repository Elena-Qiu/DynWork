Starting Python Closure container
Connecting to Clipper with default port: 7000
/usr/local/lib/python3.7/runpy.py:125: RuntimeWarning: 'clipper_admin.metrics.server' found in sys.modules after import of package 'clipper_admin.metrics', but prior to execution of 'clipper_admin.metrics.server'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
22-02-02:02:59:43 INFO     [server.py:80] Metric Server Started!
22-02-02:02:59:43 INFO     [server.py:85] Redis Connected! Waiting for messages...
Serving predictions for floats input type.
Sent heartbeat!
Received heartbeat!
Sent container metadata!
Got start of message 0 
fake_model: serving batch [[1.]
 [1.]], sleeping for 1.26ms = 0.74 + 0.26 * 2 * 1.00
fake_model: returning [1.0, 1.0]
recv: 0.000532 s, parse: 0.000012 s, handle: 0.002421 s
Got start of message 1 
fake_model: serving batch [[45.722237]
 [45.722237]], sleeping for 57.56ms = 33.88 + 0.26 * 2 * 45.72
fake_model: returning [45.722237, 45.722237]
recv: 0.000385 s, parse: 0.000010 s, handle: 0.058330 s
Got start of message 2 
fake_model: serving batch [[74.12484]
 [32.98943]], sleeping for 93.32ms = 54.93 + 0.26 * 2 * 74.12
fake_model: returning [74.12484, 32.98943]
recv: 0.000067 s, parse: 0.000002 s, handle: 0.093489 s
Got start of message 3 
fake_model: serving batch [[36.03599]], sleeping for 36.04ms = 26.70 + 0.26 * 1 * 36.04
fake_model: returning [36.03599]
recv: 0.000065 s, parse: 0.000002 s, handle: 0.036186 s
Got start of message 4 
fake_model: serving batch [[76.332214]], sleeping for 76.33ms = 56.57 + 0.26 * 1 * 76.33
fake_model: returning [76.332214]
recv: 0.000061 s, parse: 0.000002 s, handle: 0.076477 s
Got start of message 5 
fake_model: serving batch [[65.00849]], sleeping for 65.01ms = 48.17 + 0.26 * 1 * 65.01
fake_model: returning [65.00849]
recv: 0.000072 s, parse: 0.000002 s, handle: 0.065152 s
Got start of message 6 
fake_model: serving batch [[35.705025]], sleeping for 35.71ms = 26.46 + 0.26 * 1 * 35.71
fake_model: returning [35.705025]
recv: 0.000057 s, parse: 0.000002 s, handle: 0.035847 s
Got start of message 7 
fake_model: serving batch [[32.304077]], sleeping for 32.30ms = 23.94 + 0.26 * 1 * 32.30
fake_model: returning [32.304077]
recv: 0.000072 s, parse: 0.000003 s, handle: 0.032465 s
Got start of message 8 
fake_model: serving batch [[36.35692]], sleeping for 36.36ms = 26.94 + 0.26 * 1 * 36.36
fake_model: returning [36.35692]
recv: 0.000089 s, parse: 0.000002 s, handle: 0.036565 s
Got start of message 9 
fake_model: serving batch [[39.877365]], sleeping for 39.88ms = 29.55 + 0.26 * 1 * 39.88
fake_model: returning [39.877365]
recv: 0.000059 s, parse: 0.000003 s, handle: 0.040020 s
Got start of message 10 
fake_model: serving batch [[70.81624]], sleeping for 70.82ms = 52.48 + 0.26 * 1 * 70.82
fake_model: returning [70.81624]
recv: 0.000059 s, parse: 0.000002 s, handle: 0.070957 s
Got start of message 11 
fake_model: serving batch [[74.46504]], sleeping for 74.47ms = 55.18 + 0.26 * 1 * 74.47
fake_model: returning [74.46504]
recv: 0.000058 s, parse: 0.000002 s, handle: 0.074608 s
Got start of message 12 
fake_model: serving batch [[27.463676]], sleeping for 27.46ms = 20.35 + 0.26 * 1 * 27.46
fake_model: returning [27.463676]
recv: 0.000058 s, parse: 0.000002 s, handle: 0.027605 s
Got start of message 13 
fake_model: serving batch [[36.19401]], sleeping for 36.19ms = 26.82 + 0.26 * 1 * 36.19
fake_model: returning [36.19401]
recv: 0.000058 s, parse: 0.000001 s, handle: 0.036334 s
Got start of message 14 
fake_model: serving batch [[82.30217]], sleeping for 82.30ms = 60.99 + 0.26 * 1 * 82.30
fake_model: returning [82.30217]
recv: 0.000057 s, parse: 0.000002 s, handle: 0.082444 s
Got start of message 15 
fake_model: serving batch [[40.077324]], sleeping for 40.08ms = 29.70 + 0.26 * 1 * 40.08
fake_model: returning [40.077324]
recv: 0.000059 s, parse: 0.000002 s, handle: 0.040218 s
Got start of message 16 
fake_model: serving batch [[64.65245]], sleeping for 64.65ms = 47.91 + 0.26 * 1 * 64.65
fake_model: returning [64.65245]
recv: 0.000058 s, parse: 0.000002 s, handle: 0.064804 s
Got start of message 17 
fake_model: serving batch [[24.020906]], sleeping for 24.02ms = 17.80 + 0.26 * 1 * 24.02
fake_model: returning [24.020906]
recv: 0.000062 s, parse: 0.000002 s, handle: 0.024174 s
Got start of message 18 
fake_model: serving batch [[75.81282]], sleeping for 75.81ms = 56.18 + 0.26 * 1 * 75.81
fake_model: returning [75.81282]
recv: 0.000057 s, parse: 0.000002 s, handle: 0.075958 s
