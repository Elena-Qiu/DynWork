Starting Python Closure container
Connecting to Clipper with default port: 7000
/usr/local/lib/python3.7/runpy.py:125: RuntimeWarning: 'clipper_admin.metrics.server' found in sys.modules after import of package 'clipper_admin.metrics', but prior to execution of 'clipper_admin.metrics.server'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
22-02-02:00:52:29 INFO     [server.py:80] Metric Server Started!
22-02-02:00:52:29 INFO     [server.py:85] Redis Connected! Waiting for messages...
Serving predictions for floats input type.
Sent heartbeat!
Received heartbeat!
Sent container metadata!
Got start of message 0 
fake_model: serving batch [[1.]
 [1.]], sleeping for 1.26ms = 0.74 + 0.26 * 2 * 1.00
fake_model: returning [1.0, 1.0]
recv: 0.000523 s, parse: 0.000010 s, handle: 0.002467 s
Got start of message 1 
fake_model: serving batch [[80.61107]
 [80.61107]], sleeping for 101.48ms = 59.74 + 0.26 * 2 * 80.61
fake_model: returning [80.61107, 80.61107]
recv: 0.000304 s, parse: 0.000009 s, handle: 0.102182 s
Got start of message 2 
fake_model: serving batch [[51.07428]], sleeping for 51.07ms = 37.85 + 0.26 * 1 * 51.07
fake_model: returning [51.07428]
recv: 0.000073 s, parse: 0.000003 s, handle: 0.051255 s
Got start of message 3 
fake_model: serving batch [[50.76943]], sleeping for 50.77ms = 37.62 + 0.26 * 1 * 50.77
fake_model: returning [50.76943]
recv: 0.000083 s, parse: 0.000003 s, handle: 0.050972 s
Got start of message 4 
fake_model: serving batch [[78.06771]], sleeping for 78.07ms = 57.85 + 0.26 * 1 * 78.07
fake_model: returning [78.06771]
recv: 0.000071 s, parse: 0.000002 s, handle: 0.078243 s
Got start of message 5 
fake_model: serving batch [[31.244576]], sleeping for 31.24ms = 23.15 + 0.26 * 1 * 31.24
fake_model: returning [31.244576]
recv: 0.000067 s, parse: 0.000003 s, handle: 0.031407 s
Got start of message 6 
fake_model: serving batch [[87.47544]], sleeping for 87.48ms = 64.82 + 0.26 * 1 * 87.48
fake_model: returning [87.47544]
recv: 0.000063 s, parse: 0.000002 s, handle: 0.087642 s
Got start of message 7 
fake_model: serving batch [[62.839394]], sleeping for 62.84ms = 46.57 + 0.26 * 1 * 62.84
fake_model: returning [62.839394]
recv: 0.000066 s, parse: 0.000003 s, handle: 0.063006 s
Got start of message 8 
fake_model: serving batch [[82.39204]], sleeping for 82.39ms = 61.06 + 0.26 * 1 * 82.39
fake_model: returning [82.39204]
recv: 0.000068 s, parse: 0.000002 s, handle: 0.082558 s
Got start of message 9 
fake_model: serving batch [[87.13998]], sleeping for 87.14ms = 64.58 + 0.26 * 1 * 87.14
fake_model: returning [87.13998]
recv: 0.000067 s, parse: 0.000002 s, handle: 0.087307 s
Got start of message 10 
fake_model: serving batch [[29.439028]], sleeping for 29.44ms = 21.82 + 0.26 * 1 * 29.44
fake_model: returning [29.439028]
recv: 0.000063 s, parse: 0.000002 s, handle: 0.029588 s
Got start of message 11 
fake_model: serving batch [[32.759712]], sleeping for 32.76ms = 24.28 + 0.26 * 1 * 32.76
fake_model: returning [32.759712]
recv: 0.000064 s, parse: 0.000002 s, handle: 0.032907 s
Got start of message 12 
fake_model: serving batch [[33.567757]], sleeping for 33.57ms = 24.88 + 0.26 * 1 * 33.57
fake_model: returning [33.567757]
recv: 0.000068 s, parse: 0.000002 s, handle: 0.033732 s
Got start of message 13 
fake_model: serving batch [[24.939163]], sleeping for 24.94ms = 18.48 + 0.26 * 1 * 24.94
fake_model: returning [24.939163]
recv: 0.000062 s, parse: 0.000002 s, handle: 0.025087 s
Got start of message 14 
fake_model: serving batch [[22.549627]], sleeping for 22.55ms = 16.71 + 0.26 * 1 * 22.55
fake_model: returning [22.549627]
recv: 0.000066 s, parse: 0.000002 s, handle: 0.022711 s
Got start of message 15 
fake_model: serving batch [[25.403692]], sleeping for 25.40ms = 18.83 + 0.26 * 1 * 25.40
fake_model: returning [25.403692]
recv: 0.000063 s, parse: 0.000003 s, handle: 0.025551 s
Got start of message 16 
fake_model: serving batch [[80.08435]], sleeping for 80.08ms = 59.35 + 0.26 * 1 * 80.08
fake_model: returning [80.08435]
recv: 0.000063 s, parse: 0.000002 s, handle: 0.080232 s
Got start of message 17 
fake_model: serving batch [[67.883934]], sleeping for 67.88ms = 50.31 + 0.26 * 1 * 67.88
fake_model: returning [67.883934]
recv: 0.000068 s, parse: 0.000002 s, handle: 0.068045 s
Got start of message 18 
fake_model: serving batch [[88.681526]], sleeping for 88.68ms = 65.72 + 0.26 * 1 * 88.68
fake_model: returning [88.681526]
recv: 0.000064 s, parse: 0.000002 s, handle: 0.088835 s
Got start of message 19 
fake_model: serving batch [[28.59311]], sleeping for 28.59ms = 21.19 + 0.26 * 1 * 28.59
fake_model: returning [28.59311]
recv: 0.000067 s, parse: 0.000002 s, handle: 0.028755 s
Got start of message 20 
fake_model: serving batch [[28.43883]], sleeping for 28.44ms = 21.07 + 0.26 * 1 * 28.44
fake_model: returning [28.43883]
recv: 0.000079 s, parse: 0.000002 s, handle: 0.028588 s
Got start of message 21 
fake_model: serving batch [[79.258064]], sleeping for 79.26ms = 58.73 + 0.26 * 1 * 79.26
fake_model: returning [79.258064]
recv: 0.000064 s, parse: 0.000002 s, handle: 0.079412 s
Got start of message 22 
fake_model: serving batch [[26.616194]], sleeping for 26.62ms = 19.72 + 0.26 * 1 * 26.62
fake_model: returning [26.616194]
recv: 0.000063 s, parse: 0.000002 s, handle: 0.026766 s
Got start of message 23 
fake_model: serving batch [[84.5449]], sleeping for 84.54ms = 62.65 + 0.26 * 1 * 84.54
fake_model: returning [84.5449]
recv: 0.000063 s, parse: 0.000002 s, handle: 0.084693 s
Got start of message 24 
fake_model: serving batch [[58.10338]], sleeping for 58.10ms = 43.06 + 0.26 * 1 * 58.10
fake_model: returning [58.10338]
recv: 0.000063 s, parse: 0.000002 s, handle: 0.058252 s
Got start of message 25 
fake_model: serving batch [[22.134222]], sleeping for 22.13ms = 16.40 + 0.26 * 1 * 22.13
fake_model: returning [22.134222]
recv: 0.000078 s, parse: 0.000002 s, handle: 0.022282 s
Got start of message 26 
fake_model: serving batch [[51.34535]], sleeping for 51.35ms = 38.05 + 0.26 * 1 * 51.35
fake_model: returning [51.34535]
recv: 0.000063 s, parse: 0.000002 s, handle: 0.051511 s
Got start of message 27 
fake_model: serving batch [[61.708794]], sleeping for 61.71ms = 45.73 + 0.26 * 1 * 61.71
fake_model: returning [61.708794]
recv: 0.000087 s, parse: 0.000002 s, handle: 0.061923 s
Got start of message 28 
fake_model: serving batch [[21.612139]], sleeping for 21.61ms = 16.02 + 0.26 * 1 * 21.61
fake_model: returning [21.612139]
recv: 0.000063 s, parse: 0.000003 s, handle: 0.021872 s
Got start of message 29 
fake_model: serving batch [[32.532707]], sleeping for 32.53ms = 24.11 + 0.26 * 1 * 32.53
fake_model: returning [32.532707]
recv: 0.000083 s, parse: 0.000003 s, handle: 0.032705 s
Got start of message 30 
fake_model: serving batch [[76.20405]], sleeping for 76.20ms = 56.47 + 0.26 * 1 * 76.20
fake_model: returning [76.20405]
recv: 0.000078 s, parse: 0.000002 s, handle: 0.076354 s
Got start of message 31 
fake_model: serving batch [[50.098164]], sleeping for 50.10ms = 37.13 + 0.26 * 1 * 50.10
fake_model: returning [50.098164]
recv: 0.000064 s, parse: 0.000002 s, handle: 0.050259 s
Got start of message 32 
fake_model: serving batch [[61.344494]], sleeping for 61.34ms = 45.46 + 0.26 * 1 * 61.34
fake_model: returning [61.344494]
recv: 0.000072 s, parse: 0.000002 s, handle: 0.061511 s
Got start of message 33 
fake_model: serving batch [[89.815834]], sleeping for 89.82ms = 66.56 + 0.26 * 1 * 89.82
fake_model: returning [89.815834]
recv: 0.000064 s, parse: 0.000002 s, handle: 0.089971 s
Got start of message 34 
fake_model: serving batch [[60.55505]], sleeping for 60.56ms = 44.87 + 0.26 * 1 * 60.56
fake_model: returning [60.55505]
recv: 0.000063 s, parse: 0.000002 s, handle: 0.060703 s
Got start of message 35 
fake_model: serving batch [[23.61336]], sleeping for 23.61ms = 17.50 + 0.26 * 1 * 23.61
fake_model: returning [23.61336]
recv: 0.000063 s, parse: 0.000002 s, handle: 0.023763 s
Got start of message 36 
fake_model: serving batch [[27.379166]], sleeping for 27.38ms = 20.29 + 0.26 * 1 * 27.38
fake_model: returning [27.379166]
recv: 0.000078 s, parse: 0.000002 s, handle: 0.027527 s
Got start of message 37 
fake_model: serving batch [[49.752438]], sleeping for 49.75ms = 36.87 + 0.26 * 1 * 49.75
fake_model: returning [49.752438]
recv: 0.000066 s, parse: 0.000002 s, handle: 0.049914 s
Got start of message 38 
fake_model: serving batch [[75.125786]], sleeping for 75.13ms = 55.67 + 0.26 * 1 * 75.13
fake_model: returning [75.125786]
recv: 0.000068 s, parse: 0.000003 s, handle: 0.075287 s
Got start of message 39 
fake_model: serving batch [[51.838852]], sleeping for 51.84ms = 38.42 + 0.26 * 1 * 51.84
fake_model: returning [51.838852]
recv: 0.000067 s, parse: 0.000002 s, handle: 0.052004 s
Got start of message 40 
fake_model: serving batch [[85.403175]], sleeping for 85.40ms = 63.29 + 0.26 * 1 * 85.40
fake_model: returning [85.403175]
recv: 0.000064 s, parse: 0.000002 s, handle: 0.085553 s
Got start of message 41 
fake_model: serving batch [[26.99061]], sleeping for 26.99ms = 20.00 + 0.26 * 1 * 26.99
fake_model: returning [26.99061]
recv: 0.000081 s, parse: 0.000003 s, handle: 0.027154 s
