Starting Python Closure container
Connecting to Clipper with default port: 7000
/usr/local/lib/python3.7/runpy.py:125: RuntimeWarning: 'clipper_admin.metrics.server' found in sys.modules after import of package 'clipper_admin.metrics', but prior to execution of 'clipper_admin.metrics.server'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
22-01-26:15:40:35 INFO     [server.py:80] Metric Server Started!
22-01-26:15:40:35 INFO     [server.py:85] Redis Connected! Waiting for messages...
Serving predictions for floats input type.
Sent heartbeat!
Received heartbeat!
Sent container metadata!
Got start of message 0 
fake_model: serving batch [[1.]], sleeping for 1.00ms = 0.76 + 0.24 * 1 * 1.00
fake_model: returning [1.0]
recv: 0.000401 s, parse: 0.000008 s, handle: 0.001865 s
Got start of message 1 
fake_model: serving batch [[14.]], sleeping for 14.00ms = 10.69 + 0.24 * 1 * 14.00
fake_model: returning [14.0]
recv: 0.000225 s, parse: 0.000009 s, handle: 0.014457 s
Got start of message 2 
fake_model: serving batch [[4.]], sleeping for 4.00ms = 3.05 + 0.24 * 1 * 4.00
fake_model: returning [4.0]
recv: 0.000098 s, parse: 0.000004 s, handle: 0.004233 s
Got start of message 3 
fake_model: serving batch [[6.]], sleeping for 6.00ms = 4.58 + 0.24 * 1 * 6.00
fake_model: returning [6.0]
recv: 0.000204 s, parse: 0.000007 s, handle: 0.006408 s
Got start of message 4 
fake_model: serving batch [[7.]], sleeping for 7.00ms = 5.34 + 0.24 * 1 * 7.00
fake_model: returning [7.0]
recv: 0.000148 s, parse: 0.000006 s, handle: 0.007345 s
Got start of message 5 
fake_model: serving batch [[10.]], sleeping for 10.00ms = 7.63 + 0.24 * 1 * 10.00
fake_model: returning [10.0]
recv: 0.000180 s, parse: 0.000007 s, handle: 0.010414 s
Got start of message 6 
fake_model: serving batch [[4.]], sleeping for 4.00ms = 3.05 + 0.24 * 1 * 4.00
fake_model: returning [4.0]
recv: 0.000261 s, parse: 0.000008 s, handle: 0.004313 s
Got start of message 7 
fake_model: serving batch [[21.]], sleeping for 21.00ms = 16.03 + 0.24 * 1 * 21.00
fake_model: returning [21.0]
recv: 0.000190 s, parse: 0.000008 s, handle: 0.021410 s
Got start of message 8 
fake_model: serving batch [[8.]], sleeping for 8.00ms = 6.11 + 0.24 * 1 * 8.00
fake_model: returning [8.0]
recv: 0.000098 s, parse: 0.000004 s, handle: 0.008234 s
Got start of message 9 
fake_model: serving batch [[19.]], sleeping for 19.00ms = 14.50 + 0.24 * 1 * 19.00
fake_model: returning [19.0]
recv: 0.000090 s, parse: 0.000004 s, handle: 0.019227 s
Got start of message 10 
fake_model: serving batch [[11.]], sleeping for 11.00ms = 8.40 + 0.24 * 1 * 11.00
fake_model: returning [11.0]
recv: 0.000089 s, parse: 0.000004 s, handle: 0.011225 s
Got start of message 11 
fake_model: serving batch [[6.]], sleeping for 6.00ms = 4.58 + 0.24 * 1 * 6.00
fake_model: returning [6.0]
recv: 0.000091 s, parse: 0.000004 s, handle: 0.006248 s
Got start of message 12 
fake_model: serving batch [[13.]], sleeping for 13.00ms = 9.92 + 0.24 * 1 * 13.00
fake_model: returning [13.0]
recv: 0.000087 s, parse: 0.000004 s, handle: 0.013224 s
Got start of message 13 
fake_model: serving batch [[9.]], sleeping for 9.00ms = 6.87 + 0.24 * 1 * 9.00
fake_model: returning [9.0]
recv: 0.000088 s, parse: 0.000004 s, handle: 0.009222 s
Got start of message 14 
fake_model: serving batch [[12.]], sleeping for 12.00ms = 9.16 + 0.24 * 1 * 12.00
fake_model: returning [12.0]
recv: 0.000089 s, parse: 0.000004 s, handle: 0.012222 s
Got start of message 15 
fake_model: serving batch [[7.]], sleeping for 7.00ms = 5.34 + 0.24 * 1 * 7.00
fake_model: returning [7.0]
recv: 0.000090 s, parse: 0.000004 s, handle: 0.007229 s
Got start of message 16 
fake_model: serving batch [[13.]], sleeping for 13.00ms = 9.92 + 0.24 * 1 * 13.00
fake_model: returning [13.0]
recv: 0.000088 s, parse: 0.000004 s, handle: 0.013226 s
Got start of message 17 
fake_model: serving batch [[6.]], sleeping for 6.00ms = 4.58 + 0.24 * 1 * 6.00
fake_model: returning [6.0]
recv: 0.000125 s, parse: 0.000005 s, handle: 0.006256 s
Got start of message 18 
fake_model: serving batch [[14.]], sleeping for 14.00ms = 10.69 + 0.24 * 1 * 14.00
fake_model: returning [14.0]
recv: 0.000089 s, parse: 0.000004 s, handle: 0.014225 s
Got start of message 19 
fake_model: serving batch [[8.]], sleeping for 8.00ms = 6.11 + 0.24 * 1 * 8.00
fake_model: returning [8.0]
recv: 0.000089 s, parse: 0.000004 s, handle: 0.008214 s
Got start of message 20 
fake_model: serving batch [[7.]], sleeping for 7.00ms = 5.34 + 0.24 * 1 * 7.00
fake_model: returning [7.0]
recv: 0.000088 s, parse: 0.000004 s, handle: 0.007222 s
Got start of message 21 
fake_model: serving batch [[7.]], sleeping for 7.00ms = 5.34 + 0.24 * 1 * 7.00
fake_model: returning [7.0]
recv: 0.000093 s, parse: 0.000004 s, handle: 0.007227 s
Got start of message 22 
fake_model: serving batch [[19.]], sleeping for 19.00ms = 14.50 + 0.24 * 1 * 19.00
fake_model: returning [19.0]
recv: 0.000103 s, parse: 0.000005 s, handle: 0.019256 s
Got start of message 23 
fake_model: serving batch [[7.]], sleeping for 7.00ms = 5.34 + 0.24 * 1 * 7.00
fake_model: returning [7.0]
recv: 0.000101 s, parse: 0.000004 s, handle: 0.007228 s
Got start of message 24 
fake_model: serving batch [[8.]], sleeping for 8.00ms = 6.11 + 0.24 * 1 * 8.00
fake_model: returning [8.0]
recv: 0.000088 s, parse: 0.000004 s, handle: 0.008222 s
Got start of message 25 
fake_model: serving batch [[3.]], sleeping for 3.00ms = 2.29 + 0.24 * 1 * 3.00
fake_model: returning [3.0]
recv: 0.000087 s, parse: 0.000004 s, handle: 0.003223 s
Got start of message 26 
fake_model: serving batch [[11.]], sleeping for 11.00ms = 8.40 + 0.24 * 1 * 11.00
fake_model: returning [11.0]
recv: 0.000111 s, parse: 0.000004 s, handle: 0.011224 s
Got start of message 27 
fake_model: serving batch [[9.]], sleeping for 9.00ms = 6.87 + 0.24 * 1 * 9.00
fake_model: returning [9.0]
recv: 0.000087 s, parse: 0.000004 s, handle: 0.009224 s
Got start of message 28 
fake_model: serving batch [[26.]], sleeping for 26.00ms = 19.85 + 0.24 * 1 * 26.00
fake_model: returning [26.0]
recv: 0.000214 s, parse: 0.000008 s, handle: 0.026469 s
Got start of message 29 
fake_model: serving batch [[26.]], sleeping for 26.00ms = 19.85 + 0.24 * 1 * 26.00
fake_model: returning [26.0]
recv: 0.000164 s, parse: 0.000006 s, handle: 0.026347 s
Got start of message 30 
fake_model: serving batch [[ 4.]
 [ 6.]
 [10.]
 [ 7.]
 [10.]
 [12.]
 [18.]
 [11.]
 [12.]
 [ 7.]
 [ 2.]
 [ 4.]
 [ 6.]
 [13.]
 [14.]
 [18.]], sleeping for 81.88ms = 13.74 + 0.24 * 16 * 18.00
fake_model: returning [4.0, 6.0, 10.0, 7.0, 10.0, 12.0, 18.0, 11.0, 12.0, 7.0, 2.0, 4.0, 6.0, 13.0, 14.0, 18.0]
recv: 0.000144 s, parse: 0.000004 s, handle: 0.082399 s
Got start of message 31 
fake_model: serving batch [[ 7.]
 [ 3.]
 [ 6.]
 [ 4.]
 [ 5.]
 [ 5.]
 [15.]
 [13.]
 [ 2.]
 [ 7.]
 [ 5.]
 [15.]
 [12.]
 [15.]], sleeping for 61.13ms = 11.45 + 0.24 * 14 * 15.00
fake_model: returning [7.0, 3.0, 6.0, 4.0, 5.0, 5.0, 15.0, 13.0, 2.0, 7.0, 5.0, 15.0, 12.0, 15.0]
recv: 0.000128 s, parse: 0.000004 s, handle: 0.061610 s
Got start of message 32 
fake_model: serving batch [[6.]], sleeping for 6.00ms = 4.58 + 0.24 * 1 * 6.00
fake_model: returning [6.0]
recv: 0.000149 s, parse: 0.000007 s, handle: 0.006347 s
