Starting Python Closure container
Connecting to Clipper with default port: 7000
/usr/local/lib/python3.7/runpy.py:125: RuntimeWarning: 'clipper_admin.metrics.server' found in sys.modules after import of package 'clipper_admin.metrics', but prior to execution of 'clipper_admin.metrics.server'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
22-01-26:15:43:58 INFO     [server.py:80] Metric Server Started!
22-01-26:15:43:58 INFO     [server.py:85] Redis Connected! Waiting for messages...
Serving predictions for floats input type.
Sent heartbeat!
Received heartbeat!
Sent container metadata!
Got start of message 0 
fake_model: serving batch [[1.]], sleeping for 1.00ms = 0.76 + 0.24 * 1 * 1.00
fake_model: returning [1.0]
recv: 0.000398 s, parse: 0.000009 s, handle: 0.001903 s
Got start of message 1 
fake_model: serving batch [[14.]], sleeping for 14.00ms = 10.69 + 0.24 * 1 * 14.00
fake_model: returning [14.0]
recv: 0.000206 s, parse: 0.000008 s, handle: 0.014451 s
Got start of message 2 
fake_model: serving batch [[4.]], sleeping for 4.00ms = 3.05 + 0.24 * 1 * 4.00
fake_model: returning [4.0]
recv: 0.000130 s, parse: 0.000006 s, handle: 0.004290 s
Got start of message 3 
fake_model: serving batch [[6.]], sleeping for 6.00ms = 4.58 + 0.24 * 1 * 6.00
fake_model: returning [6.0]
recv: 0.000153 s, parse: 0.000007 s, handle: 0.006369 s
Got start of message 4 
fake_model: serving batch [[7.]], sleeping for 7.00ms = 5.34 + 0.24 * 1 * 7.00
fake_model: returning [7.0]
recv: 0.000160 s, parse: 0.000006 s, handle: 0.007384 s
Got start of message 5 
fake_model: serving batch [[10.]], sleeping for 10.00ms = 7.63 + 0.24 * 1 * 10.00
fake_model: returning [10.0]
recv: 0.000156 s, parse: 0.000007 s, handle: 0.010359 s
Got start of message 6 
fake_model: serving batch [[4.]], sleeping for 4.00ms = 3.05 + 0.24 * 1 * 4.00
fake_model: returning [4.0]
recv: 0.000138 s, parse: 0.000006 s, handle: 0.004325 s
Got start of message 7 
fake_model: serving batch [[21.]], sleeping for 21.00ms = 16.03 + 0.24 * 1 * 21.00
fake_model: returning [21.0]
recv: 0.000158 s, parse: 0.000006 s, handle: 0.021344 s
Got start of message 8 
fake_model: serving batch [[8.]], sleeping for 8.00ms = 6.11 + 0.24 * 1 * 8.00
fake_model: returning [8.0]
recv: 0.000102 s, parse: 0.000004 s, handle: 0.008237 s
Got start of message 9 
fake_model: serving batch [[19.]], sleeping for 19.00ms = 14.50 + 0.24 * 1 * 19.00
fake_model: returning [19.0]
recv: 0.000106 s, parse: 0.000004 s, handle: 0.019256 s
Got start of message 10 
fake_model: serving batch [[11.]], sleeping for 11.00ms = 8.40 + 0.24 * 1 * 11.00
fake_model: returning [11.0]
recv: 0.000097 s, parse: 0.000004 s, handle: 0.011248 s
Got start of message 11 
fake_model: serving batch [[6.]], sleeping for 6.00ms = 4.58 + 0.24 * 1 * 6.00
fake_model: returning [6.0]
recv: 0.000101 s, parse: 0.000004 s, handle: 0.006261 s
Got start of message 12 
fake_model: serving batch [[13.]], sleeping for 13.00ms = 9.92 + 0.24 * 1 * 13.00
fake_model: returning [13.0]
recv: 0.000114 s, parse: 0.000004 s, handle: 0.013238 s
Got start of message 13 
fake_model: serving batch [[9.]], sleeping for 9.00ms = 6.87 + 0.24 * 1 * 9.00
fake_model: returning [9.0]
recv: 0.000097 s, parse: 0.000004 s, handle: 0.009257 s
Got start of message 14 
fake_model: serving batch [[12.]], sleeping for 12.00ms = 9.16 + 0.24 * 1 * 12.00
fake_model: returning [12.0]
recv: 0.000104 s, parse: 0.000004 s, handle: 0.012245 s
Got start of message 15 
fake_model: serving batch [[7.]], sleeping for 7.00ms = 5.34 + 0.24 * 1 * 7.00
fake_model: returning [7.0]
recv: 0.000094 s, parse: 0.000004 s, handle: 0.007260 s
Got start of message 16 
fake_model: serving batch [[13.]], sleeping for 13.00ms = 9.92 + 0.24 * 1 * 13.00
fake_model: returning [13.0]
recv: 0.000104 s, parse: 0.000004 s, handle: 0.013235 s
Got start of message 17 
fake_model: serving batch [[6.]], sleeping for 6.00ms = 4.58 + 0.24 * 1 * 6.00
fake_model: returning [6.0]
recv: 0.000102 s, parse: 0.000004 s, handle: 0.006233 s
Got start of message 18 
fake_model: serving batch [[14.]], sleeping for 14.00ms = 10.69 + 0.24 * 1 * 14.00
fake_model: returning [14.0]
recv: 0.000094 s, parse: 0.000004 s, handle: 0.014240 s
Got start of message 19 
fake_model: serving batch [[8.]], sleeping for 8.00ms = 6.11 + 0.24 * 1 * 8.00
fake_model: returning [8.0]
recv: 0.000104 s, parse: 0.000004 s, handle: 0.008249 s
Got start of message 20 
fake_model: serving batch [[7.]], sleeping for 7.00ms = 5.34 + 0.24 * 1 * 7.00
fake_model: returning [7.0]
recv: 0.000105 s, parse: 0.000004 s, handle: 0.007233 s
Got start of message 21 
fake_model: serving batch [[7.]], sleeping for 7.00ms = 5.34 + 0.24 * 1 * 7.00
fake_model: returning [7.0]
recv: 0.000109 s, parse: 0.000004 s, handle: 0.007238 s
Got start of message 22 
fake_model: serving batch [[19.]], sleeping for 19.00ms = 14.50 + 0.24 * 1 * 19.00
fake_model: returning [19.0]
recv: 0.000112 s, parse: 0.000005 s, handle: 0.019279 s
Got start of message 23 
fake_model: serving batch [[7.]], sleeping for 7.00ms = 5.34 + 0.24 * 1 * 7.00
fake_model: returning [7.0]
recv: 0.000103 s, parse: 0.000004 s, handle: 0.007248 s
Got start of message 24 
fake_model: serving batch [[8.]], sleeping for 8.00ms = 6.11 + 0.24 * 1 * 8.00
fake_model: returning [8.0]
recv: 0.000097 s, parse: 0.000004 s, handle: 0.008239 s
Got start of message 25 
fake_model: serving batch [[3.]], sleeping for 3.00ms = 2.29 + 0.24 * 1 * 3.00
fake_model: returning [3.0]
recv: 0.000135 s, parse: 0.000007 s, handle: 0.003271 s
Got start of message 26 
fake_model: serving batch [[11.]], sleeping for 11.00ms = 8.40 + 0.24 * 1 * 11.00
fake_model: returning [11.0]
recv: 0.000095 s, parse: 0.000004 s, handle: 0.011250 s
Got start of message 27 
fake_model: serving batch [[9.]], sleeping for 9.00ms = 6.87 + 0.24 * 1 * 9.00
fake_model: returning [9.0]
recv: 0.000096 s, parse: 0.000004 s, handle: 0.009242 s
Got start of message 28 
fake_model: serving batch [[26.]], sleeping for 26.00ms = 19.85 + 0.24 * 1 * 26.00
fake_model: returning [26.0]
recv: 0.000169 s, parse: 0.000007 s, handle: 0.026385 s
Got start of message 29 
fake_model: serving batch [[4.]], sleeping for 4.00ms = 3.05 + 0.24 * 1 * 4.00
fake_model: returning [4.0]
recv: 0.000158 s, parse: 0.000006 s, handle: 0.004385 s
Got start of message 30 
fake_model: serving batch [[4.]], sleeping for 4.00ms = 3.05 + 0.24 * 1 * 4.00
fake_model: returning [4.0]
recv: 0.000181 s, parse: 0.000007 s, handle: 0.004416 s
Got start of message 31 
fake_model: serving batch [[19.]
 [ 4.]
 [14.]
 [ 5.]
 [ 5.]
 [18.]
 [ 5.]
 [ 3.]
 [14.]
 [ 6.]
 [14.]
 [10.]
 [17.]
 [14.]
 [20.]
 [16.]], sleeping for 90.98ms = 15.27 + 0.24 * 16 * 20.00
fake_model: returning [19.0, 4.0, 14.0, 5.0, 5.0, 18.0, 5.0, 3.0, 14.0, 6.0, 14.0, 10.0, 17.0, 14.0, 20.0, 16.0]
recv: 0.000271 s, parse: 0.000007 s, handle: 0.091969 s
Got start of message 32 
fake_model: serving batch [[15.]
 [ 2.]
 [ 7.]
 [ 5.]
 [15.]
 [12.]
 [15.]], sleeping for 36.29ms = 11.45 + 0.24 * 7 * 15.00
fake_model: returning [15.0, 2.0, 7.0, 5.0, 15.0, 12.0, 15.0]
recv: 0.000120 s, parse: 0.000004 s, handle: 0.036676 s
Got start of message 33 
fake_model: serving batch [[6.]], sleeping for 6.00ms = 4.58 + 0.24 * 1 * 6.00
fake_model: returning [6.0]
recv: 0.000138 s, parse: 0.000005 s, handle: 0.006354 s
Got start of message 34 
fake_model: serving batch [[ 8.]
 [14.]
 [13.]
 [12.]
 [15.]
 [12.]
 [18.]
 [ 8.]
 [ 5.]
 [ 9.]
 [13.]
 [11.]
 [12.]
 [11.]
 [ 3.]
 [19.]], sleeping for 86.43ms = 14.50 + 0.24 * 16 * 19.00
fake_model: returning [8.0, 14.0, 13.0, 12.0, 15.0, 12.0, 18.0, 8.0, 5.0, 9.0, 13.0, 11.0, 12.0, 11.0, 3.0, 19.0]
recv: 0.000243 s, parse: 0.000007 s, handle: 0.087279 s
