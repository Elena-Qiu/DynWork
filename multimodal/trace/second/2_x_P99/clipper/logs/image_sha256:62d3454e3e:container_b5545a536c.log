Starting Python Closure container
Connecting to Clipper with default port: 7000
/usr/local/lib/python3.7/runpy.py:125: RuntimeWarning: 'clipper_admin.metrics.server' found in sys.modules after import of package 'clipper_admin.metrics', but prior to execution of 'clipper_admin.metrics.server'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
22-01-26:16:22:55 INFO     [server.py:80] Metric Server Started!
22-01-26:16:22:55 INFO     [server.py:85] Redis Connected! Waiting for messages...
Serving predictions for floats input type.
Sent heartbeat!
Received heartbeat!
Sent container metadata!
Got start of message 0 
fake_model: serving batch [[1.]], sleeping for 1.00ms = 0.74 + 0.26 * 1 * 1.00
fake_model: returning [1.0]
recv: 0.000388 s, parse: 0.000009 s, handle: 0.001890 s
Got start of message 1 
fake_model: serving batch [[62.01225]], sleeping for 62.01ms = 45.95 + 0.26 * 1 * 62.01
fake_model: returning [62.01225]
recv: 0.000206 s, parse: 0.000009 s, handle: 0.062464 s
Got start of message 2 
fake_model: serving batch [[32.102077]
 [40.55551 ]], sleeping for 51.06ms = 30.05 + 0.26 * 2 * 40.56
fake_model: returning [32.102077, 40.55551]
recv: 0.000099 s, parse: 0.000005 s, handle: 0.051363 s
Got start of message 3 
fake_model: serving batch [[31.074528]
 [64.8114  ]], sleeping for 81.59ms = 48.03 + 0.26 * 2 * 64.81
fake_model: returning [31.074528, 64.8114]
recv: 0.000125 s, parse: 0.000004 s, handle: 0.081912 s
Got start of message 4 
fake_model: serving batch [[45.070034]
 [36.257694]
 [24.148197]], sleeping for 68.41ms = 33.40 + 0.26 * 3 * 45.07
fake_model: returning [45.070034, 36.257694, 24.148197]
recv: 0.000115 s, parse: 0.000004 s, handle: 0.068741 s
Got start of message 5 
fake_model: serving batch [[39.224785]
 [31.565899]], sleeping for 49.38ms = 29.07 + 0.26 * 2 * 39.22
fake_model: returning [39.224785, 31.565899]
recv: 0.000116 s, parse: 0.000004 s, handle: 0.049655 s
Got start of message 6 
fake_model: serving batch [[33.65192]
 [74.19709]], sleeping for 93.41ms = 54.98 + 0.26 * 2 * 74.20
fake_model: returning [33.65192, 74.19709]
recv: 0.000103 s, parse: 0.000004 s, handle: 0.093690 s
Got start of message 7 
fake_model: serving batch [[74.38224 ]
 [61.620514]
 [65.82348 ]
 [30.37427 ]
 [28.954763]
 [76.578445]
 [35.01248 ]], sleeping for 195.56ms = 56.75 + 0.26 * 7 * 76.58
fake_model: returning [74.38224, 61.620514, 65.82348, 30.37427, 28.954763, 76.578445, 35.01248]
recv: 0.000128 s, parse: 0.000004 s, handle: 0.195928 s
Got start of message 8 
fake_model: serving batch [[71.224594]
 [34.732548]
 [28.730907]
 [62.698666]
 [66.20526 ]
 [72.478386]
 [65.02428 ]
 [33.322067]], sleeping for 203.85ms = 53.71 + 0.26 * 8 * 72.48
fake_model: returning [71.224594, 34.732548, 28.730907, 62.698666, 66.20526, 72.478386, 65.02428, 33.322067]
recv: 0.000129 s, parse: 0.000005 s, handle: 0.204241 s
Got start of message 9 
fake_model: serving batch [[82.60911]], sleeping for 82.61ms = 61.22 + 0.26 * 1 * 82.61
fake_model: returning [82.60911]
recv: 0.000178 s, parse: 0.000007 s, handle: 0.082963 s
Got start of message 10 
fake_model: serving batch [[37.28956 ]
 [35.632378]
 [38.59207 ]
 [71.36741 ]
 [39.00836 ]
 [77.181854]
 [45.91591 ]
 [71.86384 ]], sleeping for 217.08ms = 57.20 + 0.26 * 8 * 77.18
fake_model: returning [37.28956, 35.632378, 38.59207, 71.36741, 39.00836, 77.181854, 45.91591, 71.86384]
recv: 0.000128 s, parse: 0.000005 s, handle: 0.217481 s
