I1211 04:19:19.256776 127213 rpc_service_base.h:46] RPC service is listening on 0.0.0.0:10001
I1211 04:19:21.823415 127218 scheduler.cpp:98] Register server: node_type: BACKEND_NODE
node_id: 2102049197
server_port: "8001"
rpc_port: "8002"
gpu_device_name: "Tesla_V100S-PCIE-32GB"
gpu_available_memory: 33650376704
gpu_uuid: "fcf0dc04-2c7f-7570-499b-47b29c6d534c"
I1211 04:19:23.272500 127219 scheduler.cpp:98] Register server: node_id: 337145073
server_port: "9001"
rpc_port: "9002"
I1211 04:19:23.273020 127221 model_db.cpp:283] Load model DB from /workdir/models/db/model_db.yml
I1211 04:19:23.273794 127221 backend_delegate.cpp:183] Backend 2102049197 loads fake:fake_0:1:224x224:993, batch 8, max batch 8, max duty cycle 3443.31 us, throughput 2323.35 req/s. Backend exec cycle 3443.31 us, duty cycle: 3443.31 us
I1211 04:19:50.259873 127213 scheduler.cpp:832] Epoch schedule
I1211 04:19:50.259984 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 1
I1211 04:19:50.260006 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/2323.35/1, total share: 1
I1211 04:20:05.261154 127213 scheduler.cpp:832] Epoch schedule
I1211 04:20:05.261232 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 7.30704 (last: 7.30704, mean: 4.90304, std: 1.76228), throughput: 2323.35
I1211 04:20:05.261291 127213 backend_delegate.cpp:341] Backend 2102049197 updates fake:fake_0:1:224x224:993, batch 8, max batch 8, new throughput 8.10173
I1211 04:20:05.262663 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00348709
I1211 04:20:05.262686 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/8.10173/1, total share: 1
I1211 04:20:35.264915 127213 scheduler.cpp:832] Epoch schedule
I1211 04:20:35.265007 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 7.91583 (last: 7.91583, mean: 7.41002, std: 0.297796), throughput: 8.10173
I1211 04:20:35.265061 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00348709
I1211 04:20:35.265085 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/8.10173/1, total share: 1
I1211 04:21:05.267395 127213 scheduler.cpp:832] Epoch schedule
I1211 04:21:05.267479 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 7.23357 (last: 7.23357, mean: 7.9071, std: 0.436974), throughput: 8.10173
I1211 04:21:05.268237 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00348709
I1211 04:21:05.268260 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/8.10173/1, total share: 1
I1211 04:21:18.269316 127213 scheduler.cpp:832] Epoch schedule
I1211 04:21:18.269352 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 6.41233 (last: 6.41233, mean: 7.51087, std: 0.498153), throughput: 8.10173
I1211 04:21:18.269390 127213 backend_delegate.cpp:341] Backend 2102049197 updates fake:fake_0:1:224x224:993, batch 7, max batch 8, new throughput 7.08665
I1211 04:21:18.270514 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00315318
I1211 04:21:18.270538 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/7.08665/1, total share: 1
I1211 04:21:28.271378 127213 scheduler.cpp:832] Epoch schedule
I1211 04:21:28.271417 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 4.64786 (last: 4.64786, mean: 6.70445, std: 0.900735), throughput: 7.08665
I1211 04:21:28.271451 127213 backend_delegate.cpp:341] Backend 2102049197 updates fake:fake_0:1:224x224:993, batch 5, max batch 8, new throughput 5.05853
I1211 04:21:28.272503 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00248601
I1211 04:21:28.272526 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/5.05853/1, total share: 1
I1211 04:21:38.273437 127213 scheduler.cpp:832] Epoch schedule
I1211 04:21:38.273481 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 3.06776 (last: 3.06776, mean: 5.49671, std: 1.5153), throughput: 5.05853
I1211 04:21:38.273519 127213 backend_delegate.cpp:341] Backend 2102049197 updates fake:fake_0:1:224x224:993, batch 4, max batch 8, new throughput 4.04548
I1211 04:21:38.274240 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00215276
I1211 04:21:38.274260 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/4.04548/1, total share: 1
I1211 04:21:48.275241 127213 scheduler.cpp:832] Epoch schedule
I1211 04:21:48.275264 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 2.17045 (last: 2.17045, mean: 3.95031, std: 1.36811), throughput: 4.04548
I1211 04:21:48.275285 127213 backend_delegate.cpp:341] Backend 2102049197 updates fake:fake_0:1:224x224:993, batch 3, max batch 8, new throughput 3.0331
I1211 04:21:48.275915 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00181973
I1211 04:21:48.275934 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/3.0331/1, total share: 1
I1211 04:21:58.276773 127213 scheduler.cpp:832] Epoch schedule
I1211 04:21:58.276806 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 1.94932 (last: 1.94932, mean: 2.78916, std: 0.757514), throughput: 3.0331
I1211 04:21:58.276834 127213 backend_delegate.cpp:341] Backend 2102049197 updates fake:fake_0:1:224x224:993, batch 2, max batch 8, new throughput 2.02139
I1211 04:21:58.277619 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00148693
I1211 04:21:58.277639 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/2.02139/1, total share: 1
I1211 04:22:28.280381 127213 scheduler.cpp:832] Epoch schedule
I1211 04:22:28.280426 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 1.6293 (last: 1.6293, mean: 1.72537, std: 0.0749611), throughput: 2.02139
I1211 04:22:28.281049 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00148693
I1211 04:22:28.281080 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/2.02139/1, total share: 1
I1211 04:22:40.282172 127213 scheduler.cpp:832] Epoch schedule
I1211 04:22:40.282193 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 1.61412 (last: 1.61412, mean: 1.66521, std: 0.0544568), throughput: 2.02139
I1211 04:22:40.282567 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00148693
I1211 04:22:40.282586 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/2.02139/1, total share: 1
I1211 04:22:50.283596 127213 scheduler.cpp:832] Epoch schedule
I1211 04:22:50.283627 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 1.55777 (last: 1.55777, mean: 1.61982, std: 0.0431404), throughput: 2.02139
I1211 04:22:50.284152 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00148693
I1211 04:22:50.284171 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/2.02139/1, total share: 1
I1211 04:23:00.285082 127213 scheduler.cpp:832] Epoch schedule
I1211 04:23:00.285120 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 1.58744 (last: 1.58744, mean: 1.58765, std: 0.0339333), throughput: 2.02139
I1211 04:23:00.285491 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00148693
I1211 04:23:00.285509 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/2.02139/1, total share: 1
I1211 04:23:10.286283 127213 scheduler.cpp:832] Epoch schedule
I1211 04:23:10.286306 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 1.55507 (last: 1.55507, mean: 1.58199, std: 0.0323478), throughput: 2.02139
I1211 04:23:10.286705 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00148693
I1211 04:23:10.286723 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/2.02139/1, total share: 1
I1211 04:23:20.287479 127213 scheduler.cpp:832] Epoch schedule
I1211 04:23:20.287508 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 2.53406 (last: 2.53406, mean: 1.76337, std: 0.324614), throughput: 2.02139
I1211 04:23:20.287534 127213 backend_delegate.cpp:341] Backend 2102049197 updates fake:fake_0:1:224x224:993, batch 3, max batch 8, new throughput 3.0331
I1211 04:23:20.288501 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00181973
I1211 04:23:20.288520 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/3.0331/1, total share: 1
I1211 04:23:30.289302 127213 scheduler.cpp:832] Epoch schedule
I1211 04:23:30.289348 127213 scheduler.cpp:861] fake:fake_0:1:224x224:993 estimate rps: 5.53391 (last: 5.53391, mean: 2.67502, std: 1.31296), throughput: 3.0331
I1211 04:23:30.289374 127213 backend_delegate.cpp:341] Backend 2102049197 updates fake:fake_0:1:224x224:993, batch 6, max batch 8, new throughput 6.07225
I1211 04:23:30.290086 127213 scheduler.cpp:1120] Total used GPUs: 1
Backend 2102049197: 0.00281948
I1211 04:23:30.290107 127213 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:993: 2102049197/6.07225/1, total share: 1
*** Aborted at 1639196612 (unix time) try "date -d @1639196612" if you are using GNU date ***
I1211 04:23:32.921064 127218 scheduler.cpp:115] Unregister BACKEND_NODE 2102049197
I1211 04:23:32.921144 127218 scheduler.cpp:454] Remove backend 2102049197
I1211 04:23:32.921176 127218 scheduler.cpp:984] fake:fake_0:1:224x224:993 has unassigned workload 6.07225
I1211 04:23:32.921202 127218 scheduler.cpp:1007] Unassigned workload fake:fake_0:1:224x224:993, 6.07225 req/s
I1211 04:23:32.921205 127220 scheduler.cpp:115] Unregister FRONTEND_NODE 337145073
PC: @                0x0 (unknown)
*** SIGTERM (@0x1f0ab) received by PID 127213 (TID 0x7f31753cbf00) from PID 127147; stack trace: ***
    @     0x7f31740ca980 (unknown)
    @     0x7f31740c9d50 __GI___nanosleep
    @     0x55b5e721cf0d std::this_thread::sleep_for<>()
    @     0x55b5e7200269 nexus::scheduler::Scheduler::Run()
    @     0x55b5e724f781 main
    @     0x7f316f33fbf7 __libc_start_main
    @     0x55b5e71cbeaa _start
    @                0x0 (unknown)
