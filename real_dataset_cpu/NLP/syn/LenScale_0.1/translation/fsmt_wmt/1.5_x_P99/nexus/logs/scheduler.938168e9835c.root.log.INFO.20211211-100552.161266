Log file created at: 2021/12/11 10:05:52
Running on machine: 938168e9835c
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1211 10:05:52.539799 161266 rpc_service_base.h:46] RPC service is listening on 0.0.0.0:10001
I1211 10:05:55.107479 161271 scheduler.cpp:98] Register server: node_type: BACKEND_NODE
node_id: 610616001
server_port: "8001"
rpc_port: "8002"
gpu_device_name: "Tesla_V100S-PCIE-32GB"
gpu_available_memory: 33650376704
gpu_uuid: "fcf0dc04-2c7f-7570-499b-47b29c6d534c"
I1211 10:05:56.556303 161271 scheduler.cpp:98] Register server: node_id: 2985271
server_port: "9001"
rpc_port: "9002"
I1211 10:05:56.556739 161272 model_db.cpp:283] Load model DB from /workdir/models/db/model_db.yml
I1211 10:05:56.557531 161272 backend_delegate.cpp:183] Backend 610616001 loads fake:fake_0:1:224x224:701, batch 8, max batch 8, max duty cycle 2088.45 us, throughput 3830.6 req/s. Backend exec cycle 2088.45 us, duty cycle: 2088.45 us
I1211 10:06:23.543386 161266 scheduler.cpp:832] Epoch schedule
I1211 10:06:23.543496 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 1
I1211 10:06:23.543514 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/3830.6/1, total share: 1
I1211 10:06:38.544734 161266 scheduler.cpp:832] Epoch schedule
I1211 10:06:38.544828 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 4.72657 (last: 4.72657, mean: 3.25336, std: 1.44279), throughput: 3830.6
I1211 10:06:38.544883 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 4, max batch 8, new throughput 5.73451
I1211 10:06:38.546551 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00194413
I1211 10:06:38.546573 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/5.73451/1, total share: 1
I1211 10:06:48.547308 161266 scheduler.cpp:832] Epoch schedule
I1211 10:06:48.547351 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 2.66132 (last: 2.66132, mean: 3.87617, std: 0.91445), throughput: 5.73451
I1211 10:06:48.548278 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 2, max batch 8, new throughput 2.86575
I1211 10:06:48.548939 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00141843
I1211 10:06:48.548959 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/2.86575/1, total share: 1
I1211 10:06:58.549700 161266 scheduler.cpp:832] Epoch schedule
I1211 10:06:58.549759 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 1.42865 (last: 1.42865, mean: 3.25952, std: 1.20697), throughput: 2.86575
I1211 10:06:58.549780 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 1, max batch 8, new throughput 1.4325
I1211 10:06:58.550359 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00115578
I1211 10:06:58.550379 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/1.4325/1, total share: 1
I1211 10:07:08.551103 161266 scheduler.cpp:832] Epoch schedule
I1211 10:07:08.551139 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 2.69503 (last: 2.69503, mean: 2.46004, std: 0.839227), throughput: 1.4325
I1211 10:07:08.551163 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 2, max batch 8, new throughput 2.86575
I1211 10:07:08.551709 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00141843
I1211 10:07:08.551728 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/2.86575/1, total share: 1
I1211 10:07:18.552510 161266 scheduler.cpp:832] Epoch schedule
I1211 10:07:18.552584 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 3.89114 (last: 3.89114, mean: 2.29466, std: 0.678004), throughput: 2.86575
I1211 10:07:18.552624 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 3, max batch 8, new throughput 4.29975
I1211 10:07:18.553465 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00168121
I1211 10:07:18.553498 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/4.29975/1, total share: 1
I1211 10:07:31.554455 161266 scheduler.cpp:832] Epoch schedule
I1211 10:07:31.554560 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 5.22455 (last: 5.22455, mean: 3.02913, std: 0.828663), throughput: 4.29975
I1211 10:07:31.554594 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 4, max batch 8, new throughput 5.73451
I1211 10:07:31.555415 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00194413
I1211 10:07:31.555436 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/5.73451/1, total share: 1
I1211 10:07:41.556236 161266 scheduler.cpp:832] Epoch schedule
I1211 10:07:41.556301 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 4.52113 (last: 4.52113, mean: 4.06824, std: 1.13656), throughput: 5.73451
I1211 10:07:41.556777 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00194413
I1211 10:07:41.556797 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/5.73451/1, total share: 1
I1211 10:07:51.557641 161266 scheduler.cpp:832] Epoch schedule
I1211 10:07:51.557680 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 3.65128 (last: 3.65128, mean: 4.28715, std: 0.948492), throughput: 5.73451
I1211 10:07:51.557705 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 3, max batch 8, new throughput 4.29975
I1211 10:07:51.558321 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00168121
I1211 10:07:51.558341 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/4.29975/1, total share: 1
I1211 10:08:13.560072 161266 scheduler.cpp:832] Epoch schedule
I1211 10:08:13.560163 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 3.43404 (last: 3.43404, mean: 3.80074, std: 0.226656), throughput: 4.29975
I1211 10:08:13.560793 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00168121
I1211 10:08:13.560813 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/4.29975/1, total share: 1
I1211 10:08:23.561573 161266 scheduler.cpp:832] Epoch schedule
I1211 10:08:23.561640 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 2.58046 (last: 2.58046, mean: 3.60079, std: 0.417759), throughput: 4.29975
I1211 10:08:23.561681 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 2, max batch 8, new throughput 2.86575
I1211 10:08:23.562346 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00141843
I1211 10:08:23.562376 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/2.86575/1, total share: 1
I1211 10:08:33.563093 161266 scheduler.cpp:832] Epoch schedule
I1211 10:08:33.563141 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 2.22135 (last: 2.22135, mean: 3.14894, std: 0.620074), throughput: 2.86575
I1211 10:08:33.563544 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00141843
I1211 10:08:33.563573 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/2.86575/1, total share: 1
I1211 10:08:43.564263 161266 scheduler.cpp:832] Epoch schedule
I1211 10:08:43.564321 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 2.16922 (last: 2.16922, mean: 2.58801, std: 0.449689), throughput: 2.86575
I1211 10:08:43.564688 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00141843
I1211 10:08:43.564707 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/2.86575/1, total share: 1
I1211 10:08:53.565451 161266 scheduler.cpp:832] Epoch schedule
I1211 10:08:53.565485 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 1.77575 (last: 1.77575, mean: 2.17413, std: 0.269052), throughput: 2.86575
I1211 10:08:53.565863 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00141843
I1211 10:08:53.565893 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/2.86575/1, total share: 1
I1211 10:09:03.566632 161266 scheduler.cpp:832] Epoch schedule
I1211 10:09:03.566692 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 3.78375 (last: 3.78375, mean: 2.29079, std: 0.538153), throughput: 2.86575
I1211 10:09:03.566717 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 3, max batch 8, new throughput 4.29975
I1211 10:09:03.567392 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00168121
I1211 10:09:03.567411 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/4.29975/1, total share: 1
I1211 10:09:13.568141 161266 scheduler.cpp:832] Epoch schedule
I1211 10:09:13.568219 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 1.84157 (last: 1.84157, mean: 2.45624, std: 0.643709), throughput: 4.29975
I1211 10:09:13.568241 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 2, max batch 8, new throughput 2.86575
I1211 10:09:13.568936 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00141843
I1211 10:09:13.568954 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/2.86575/1, total share: 1
I1211 10:09:24.569748 161266 scheduler.cpp:832] Epoch schedule
I1211 10:09:24.569788 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 3.28413 (last: 3.28413, mean: 2.57326, std: 0.658722), throughput: 2.86575
I1211 10:09:24.569813 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 3, max batch 8, new throughput 4.29975
I1211 10:09:24.570384 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00168121
I1211 10:09:24.570405 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/4.29975/1, total share: 1
I1211 10:09:34.571108 161266 scheduler.cpp:832] Epoch schedule
I1211 10:09:34.571161 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 2.08332 (last: 2.08332, mean: 2.43617, std: 0.540954), throughput: 4.29975
I1211 10:09:34.571182 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 2, max batch 8, new throughput 2.86575
I1211 10:09:34.571943 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00141843
I1211 10:09:34.571972 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/2.86575/1, total share: 1
I1211 10:09:44.572697 161266 scheduler.cpp:832] Epoch schedule
I1211 10:09:44.572773 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 3.73419 (last: 3.73419, mean: 2.53096, std: 0.681451), throughput: 2.86575
I1211 10:09:44.572816 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 3, max batch 8, new throughput 4.29975
I1211 10:09:44.573642 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00168121
I1211 10:09:44.573660 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/4.29975/1, total share: 1
I1211 10:09:54.574457 161266 scheduler.cpp:832] Epoch schedule
I1211 10:09:54.574509 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 2.62836 (last: 2.62836, mean: 2.88762, std: 0.660593), throughput: 4.29975
I1211 10:09:54.574532 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 2, max batch 8, new throughput 2.86575
I1211 10:09:54.575137 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00141843
I1211 10:09:54.575156 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/2.86575/1, total share: 1
I1211 10:10:06.576195 161266 scheduler.cpp:832] Epoch schedule
I1211 10:10:06.576243 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 3.69214 (last: 3.69214, mean: 2.85536, std: 0.687458), throughput: 2.86575
I1211 10:10:06.576282 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 3, max batch 8, new throughput 4.29975
I1211 10:10:06.576890 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00168121
I1211 10:10:06.576922 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/4.29975/1, total share: 1
I1211 10:10:20.578181 161266 scheduler.cpp:832] Epoch schedule
I1211 10:10:20.578263 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 3.39872 (last: 3.39872, mean: 3.47839, std: 1.20709), throughput: 4.29975
I1211 10:10:20.578871 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00168121
I1211 10:10:20.578891 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/4.29975/1, total share: 1
I1211 10:10:30.579950 161266 scheduler.cpp:832] Epoch schedule
I1211 10:10:30.579993 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 1.91256 (last: 1.91256, mean: 3.48205, std: 1.21524), throughput: 4.29975
I1211 10:10:30.580030 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 2, max batch 8, new throughput 2.86575
I1211 10:10:30.580730 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00141843
I1211 10:10:30.580749 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/2.86575/1, total share: 1
I1211 10:10:40.581557 161266 scheduler.cpp:832] Epoch schedule
I1211 10:10:40.581589 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 3.42145 (last: 3.42145, mean: 3.31561, std: 1.05151), throughput: 2.86575
I1211 10:10:40.581612 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 3, max batch 8, new throughput 4.29975
I1211 10:10:40.582190 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00168121
I1211 10:10:40.582209 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/4.29975/1, total share: 1
I1211 10:10:54.583392 161266 scheduler.cpp:832] Epoch schedule
I1211 10:10:54.583462 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 3.3332 (last: 3.3332, mean: 3.3041, std: 1.01465), throughput: 4.29975
I1211 10:10:54.583868 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00168121
I1211 10:10:54.583899 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/4.29975/1, total share: 1
I1211 10:11:04.584862 161266 scheduler.cpp:832] Epoch schedule
I1211 10:11:04.584892 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 1.75635 (last: 1.75635, mean: 3.3541, std: 0.992384), throughput: 4.29975
I1211 10:11:04.584915 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 2, max batch 8, new throughput 2.86575
I1211 10:11:04.585532 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00141843
I1211 10:11:04.585552 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/2.86575/1, total share: 1
I1211 10:11:14.586589 161266 scheduler.cpp:832] Epoch schedule
I1211 10:11:14.586652 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 1.19161 (last: 1.19161, mean: 2.75749, std: 1.29869), throughput: 2.86575
I1211 10:11:14.586679 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 1, max batch 8, new throughput 1.4325
I1211 10:11:14.587450 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00115578
I1211 10:11:14.587469 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/1.4325/1, total share: 1
I1211 10:11:24.588462 161266 scheduler.cpp:832] Epoch schedule
I1211 10:11:24.588526 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 0.635519 (last: 0.635519, mean: 1.60056, std: 0.718891), throughput: 1.4325
I1211 10:11:24.588886 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00115578
I1211 10:11:24.588905 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/1.4325/1, total share: 1
I1211 10:11:34.589784 161266 scheduler.cpp:832] Epoch schedule
I1211 10:11:34.589824 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 0.565645 (last: 0.565645, mean: 1.00155, std: 0.440102), throughput: 1.4325
I1211 10:11:34.590147 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00115578
I1211 10:11:34.590184 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/1.4325/1, total share: 1
I1211 10:11:44.591082 161266 scheduler.cpp:832] Epoch schedule
I1211 10:11:44.591114 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 0.666767 (last: 0.666767, mean: 0.760514, std: 0.177701), throughput: 1.4325
I1211 10:11:44.591542 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00115578
I1211 10:11:44.591560 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/1.4325/1, total share: 1
I1211 10:11:54.592603 161266 scheduler.cpp:832] Epoch schedule
I1211 10:11:54.592679 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 1.08478 (last: 1.08478, mean: 0.733068, std: 0.159217), throughput: 1.4325
I1211 10:11:54.593065 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00115578
I1211 10:11:54.593096 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/1.4325/1, total share: 1
I1211 10:12:04.594074 161266 scheduler.cpp:832] Epoch schedule
I1211 10:12:04.594112 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 1.76514 (last: 1.76514, mean: 1.06883, std: 0.443681), throughput: 1.4325
I1211 10:12:04.594136 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 2, max batch 8, new throughput 2.86575
I1211 10:12:04.594841 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00141843
I1211 10:12:04.594862 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/2.86575/1, total share: 1
I1211 10:12:14.595728 161266 scheduler.cpp:832] Epoch schedule
I1211 10:12:14.595788 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 2.26337 (last: 2.26337, mean: 1.52603, std: 0.651418), throughput: 2.86575
I1211 10:12:14.596123 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00141843
I1211 10:12:14.596143 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/2.86575/1, total share: 1
I1211 10:12:24.596840 161266 scheduler.cpp:832] Epoch schedule
I1211 10:12:24.596880 161266 scheduler.cpp:861] fake:fake_0:1:224x224:701 estimate rps: 1.31006 (last: 1.31006, mean: 1.81966, std: 0.409811), throughput: 2.86575
I1211 10:12:24.596904 161266 backend_delegate.cpp:341] Backend 610616001 updates fake:fake_0:1:224x224:701, batch 1, max batch 8, new throughput 1.4325
I1211 10:12:24.597460 161266 scheduler.cpp:1120] Total used GPUs: 1
Backend 610616001: 0.00115578
I1211 10:12:24.597479 161266 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:701: 610616001/1.4325/1, total share: 1
I1211 10:12:29.396278 161271 scheduler.cpp:115] Unregister BACKEND_NODE 610616001
I1211 10:12:29.396311 161271 scheduler.cpp:454] Remove backend 610616001
I1211 10:12:29.396338 161271 scheduler.cpp:984] fake:fake_0:1:224x224:701 has unassigned workload 1.4325
I1211 10:12:29.396359 161271 scheduler.cpp:1007] Unassigned workload fake:fake_0:1:224x224:701, 1.4325 req/s
I1211 10:12:29.396450 161274 scheduler.cpp:115] Unregister FRONTEND_NODE 2985271
