Log file created at: 2021/12/11 01:50:13
Running on machine: 938168e9835c
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1211 01:50:13.935362 99851 rpc_service_base.h:46] RPC service is listening on 0.0.0.0:10001
I1211 01:50:16.494144 99856 scheduler.cpp:98] Register server: node_type: BACKEND_NODE
node_id: 2531152608
server_port: "8001"
rpc_port: "8002"
gpu_device_name: "Tesla_V100S-PCIE-32GB"
gpu_available_memory: 33650376704
gpu_uuid: "fcf0dc04-2c7f-7570-499b-47b29c6d534c"
I1211 01:50:17.952582 99858 scheduler.cpp:98] Register server: node_id: 2665333294
server_port: "9001"
rpc_port: "9002"
I1211 01:50:17.953061 99859 model_db.cpp:283] Load model DB from /workdir/models/db/model_db.yml
I1211 01:50:17.953850 99859 backend_delegate.cpp:183] Backend 2531152608 loads fake:fake_0:1:224x224:56, batch 8, max batch 8, max duty cycle 117.382 us, throughput 68153.4 req/s. Backend exec cycle 117.382 us, duty cycle: 117.382 us
I1211 01:50:44.938791 99851 scheduler.cpp:832] Epoch schedule
I1211 01:50:44.938894 99851 scheduler.cpp:1120] Total used GPUs: 1
Backend 2531152608: 1
I1211 01:50:44.938912 99851 scheduler.cpp:1137] Model table: 
fake:fake_0:1:224x224:56: 2531152608/68153.4/1, total share: 1
I1211 01:50:46.132468 99859 scheduler.cpp:115] Unregister BACKEND_NODE 2531152608
I1211 01:50:46.132532 99859 scheduler.cpp:454] Remove backend 2531152608
I1211 01:50:46.132534 99856 scheduler.cpp:115] Unregister FRONTEND_NODE 2665333294
I1211 01:50:46.132565 99859 scheduler.cpp:984] fake:fake_0:1:224x224:56 has unassigned workload 68153.4
I1211 01:50:46.132648 99859 scheduler.cpp:1007] Unassigned workload fake:fake_0:1:224x224:56, 68153.4 req/s
